[2022-06-12 21:09:37,689] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: T-dbt-job-dimensions.dbt_clone_and_transform-dimensions scheduled__2022-06-12T19:09:30.915751+00:00 [queued]>
[2022-06-12 21:09:37,699] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: T-dbt-job-dimensions.dbt_clone_and_transform-dimensions scheduled__2022-06-12T19:09:30.915751+00:00 [queued]>
[2022-06-12 21:09:37,700] {taskinstance.py:1356} INFO - 
--------------------------------------------------------------------------------
[2022-06-12 21:09:37,700] {taskinstance.py:1357} INFO - Starting attempt 1 of 2
[2022-06-12 21:09:37,700] {taskinstance.py:1358} INFO - 
--------------------------------------------------------------------------------
[2022-06-12 21:09:37,720] {taskinstance.py:1377} INFO - Executing <Task(BashOperator): dbt_clone_and_transform-dimensions> on 2022-06-12 19:09:30.915751+00:00
[2022-06-12 21:09:37,728] {standard_task_runner.py:52} INFO - Started process 64 to run task
[2022-06-12 21:09:37,734] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'T-dbt-job-dimensions', 'dbt_clone_and_transform-dimensions', 'scheduled__2022-06-12T19:09:30.915751+00:00', '--job-id', '10', '--raw', '--subdir', 'DAGS_FOLDER/docker_job/dbt_model.py', '--cfg-path', '/tmp/tmpaipfab95', '--error-file', '/tmp/tmppjn27qi1']
[2022-06-12 21:09:37,734] {standard_task_runner.py:80} INFO - Job 10: Subtask dbt_clone_and_transform-dimensions
[2022-06-12 21:09:37,749] {warnings.py:110} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525: DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
  option = self._get_environment_variables(deprecated_key, deprecated_section, key, section)

[2022-06-12 21:09:37,794] {task_command.py:370} INFO - Running <TaskInstance: T-dbt-job-dimensions.dbt_clone_and_transform-dimensions scheduled__2022-06-12T19:09:30.915751+00:00 [running]> on host 8425e4f159a6
[2022-06-12 21:09:37,888] {taskinstance.py:1571} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=samuelolle@yahoo.com
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=T-dbt-job-dimensions
AIRFLOW_CTX_TASK_ID=dbt_clone_and_transform-dimensions
AIRFLOW_CTX_EXECUTION_DATE=2022-06-12T19:09:30.915751+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-12T19:09:30.915751+00:00
[2022-06-12 21:09:37,890] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-06-12 21:09:37,890] {subprocess.py:74} INFO - Running command: ['bash', '-c', " rm -rf /tmp/dimensions && mkdir /tmp/dimensions                            && cp -r /tmp/dbt /tmp/dimensions/dbt                             && cd /tmp/dimensions/dbt && python3 -m venv venv                             && export PIP_USER=false                             && *** /tmp/dimensions/dbt/venv/bin/activate                             && pip  install --quiet --upgrade pip setuptools                             && pip3 install --quiet 'MarkupSafe<=2.0.1' 'dbt-postgres' 'dbt-core'                             && dbt --version && deactivate                             && cd /tmp/dimensions/dbt && *** /tmp/dimensions/dbt/venv/bin/activate                             && dbt deps --profiles-dir /tmp/dimensions/dbt/ && dbt seed --profiles-dir /tmp/dimensions/dbt/                             && dbt run --models dimensions --profiles-dir /tmp/dimensions/dbt/"]
[2022-06-12 21:09:37,920] {subprocess.py:85} INFO - Output:
[2022-06-12 21:09:44,429] {subprocess.py:92} INFO - WARNING: Error parsing requirements for setuptools: [Errno 2] No such file or directory: '/tmp/dimensions/dbt/venv/lib/python3.7/site-packages/setuptools-47.1.0.dist-info/METADATA'
[2022-06-12 21:09:44,429] {subprocess.py:92} INFO - WARNING: Error parsing requirements for pip: [Errno 2] No such file or directory: '/tmp/dimensions/dbt/venv/lib/python3.7/site-packages/pip-22.0.4.dist-info/METADATA'
[2022-06-12 21:09:44,497] {subprocess.py:92} INFO - ERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory
[2022-06-12 21:09:44,498] {subprocess.py:92} INFO - 
[2022-06-12 21:09:44,683] {subprocess.py:96} INFO - Command exited with return code 1
[2022-06-12 21:09:44,703] {taskinstance.py:1889} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/bash.py", line 195, in execute
    f'Bash command failed. The command returned a non-zero exit code {result.exit_code}.'
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2022-06-12 21:09:44,708] {taskinstance.py:1400} INFO - Marking task as UP_FOR_RETRY. dag_id=T-dbt-job-dimensions, task_id=dbt_clone_and_transform-dimensions, execution_date=20220612T190930, start_date=20220612T210937, end_date=20220612T210944
[2022-06-12 21:09:44,730] {standard_task_runner.py:97} ERROR - Failed to execute job 10 for task dbt_clone_and_transform-dimensions (Bash command failed. The command returned a non-zero exit code 1.; 64)
[2022-06-12 21:09:44,780] {local_task_job.py:156} INFO - Task exited with return code 1
[2022-06-12 21:09:44,845] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
