[2022-06-18 00:04:17,709] {processor.py:153} INFO - Started process (PID=9510) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 00:04:17,837] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 00:04:17,837] {logging_mixin.py:115} INFO - [2022-06-18 00:04:17,837] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 00:04:19,080] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 00:13:59,764] {processor.py:153} INFO - Started process (PID=9621) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 00:13:59,769] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 00:13:59,770] {logging_mixin.py:115} INFO - [2022-06-18 00:13:59,770] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 00:14:00,254] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 00:15:24,991] {logging_mixin.py:115} INFO - [2022-06-18 00:15:24,990] {dag.py:2379} INFO - Sync 3 DAGs
[2022-06-18 00:15:27,626] {logging_mixin.py:115} INFO - [2022-06-18 00:15:27,546] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-dimensions to 2022-06-17T22:15:27.294391+00:00, run_after=2022-06-18T00:15:27.294391+00:00
[2022-06-18 00:15:27,759] {logging_mixin.py:115} INFO - [2022-06-18 00:15:27,695] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-example to 2022-06-17T22:15:27.636851+00:00, run_after=2022-06-18T00:15:27.636851+00:00
[2022-06-18 00:15:27,761] {logging_mixin.py:115} INFO - [2022-06-18 00:15:27,761] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-objects to 2022-06-17T22:15:27.761407+00:00, run_after=2022-06-18T00:15:27.761407+00:00
[2022-06-18 00:17:54,767] {processor.py:153} INFO - Started process (PID=9665) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 00:17:55,148] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 00:17:56,932] {logging_mixin.py:115} INFO - [2022-06-18 00:17:56,756] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 00:18:03,984] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 00:23:43,399] {processor.py:153} INFO - Started process (PID=9837) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 00:23:43,403] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 00:23:43,404] {logging_mixin.py:115} INFO - [2022-06-18 00:23:43,404] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 00:23:43,958] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 00:24:01,898] {logging_mixin.py:115} INFO - [2022-06-18 00:24:01,760] {dag.py:2379} INFO - Sync 3 DAGs
[2022-06-18 00:24:12,995] {logging_mixin.py:115} INFO - [2022-06-18 00:24:12,995] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-dimensions to 2022-06-17T22:24:12.961038+00:00, run_after=2022-06-18T00:24:12.961038+00:00
[2022-06-18 00:24:12,996] {logging_mixin.py:115} INFO - [2022-06-18 00:24:12,996] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-example to 2022-06-17T22:24:12.996106+00:00, run_after=2022-06-18T00:24:12.996106+00:00
[2022-06-18 00:24:12,996] {logging_mixin.py:115} INFO - [2022-06-18 00:24:12,996] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-objects to 2022-06-17T22:24:12.996451+00:00, run_after=2022-06-18T00:24:12.996451+00:00
[2022-06-18 00:24:13,654] {processor.py:161} INFO - Processing /opt/airflow/dags/docker_job/dbt_model.py took 30.288 seconds
[2022-06-18 00:28:19,088] {processor.py:153} INFO - Started process (PID=9933) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 00:28:19,089] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 00:28:19,090] {logging_mixin.py:115} INFO - [2022-06-18 00:28:19,090] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 00:28:20,243] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 00:28:55,381] {logging_mixin.py:115} INFO - [2022-06-18 00:28:54,845] {dag.py:2379} INFO - Sync 3 DAGs
[2022-06-18 00:35:09,785] {processor.py:153} INFO - Started process (PID=10098) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 00:35:09,808] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 00:35:09,809] {logging_mixin.py:115} INFO - [2022-06-18 00:35:09,809] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 00:35:10,798] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 00:35:14,751] {logging_mixin.py:115} INFO - [2022-06-18 00:35:14,751] {dag.py:2379} INFO - Sync 3 DAGs
[2022-06-18 00:35:15,587] {logging_mixin.py:115} INFO - [2022-06-18 00:35:15,565] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-dimensions to 2022-06-17T22:35:15.272648+00:00, run_after=2022-06-18T00:35:15.272648+00:00
[2022-06-18 00:35:15,789] {logging_mixin.py:115} INFO - [2022-06-18 00:35:15,749] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-example to 2022-06-17T22:35:15.688448+00:00, run_after=2022-06-18T00:35:15.688448+00:00
[2022-06-18 00:35:15,805] {logging_mixin.py:115} INFO - [2022-06-18 00:35:15,804] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-objects to 2022-06-17T22:35:15.804818+00:00, run_after=2022-06-18T00:35:15.804818+00:00
[2022-06-18 00:35:18,162] {processor.py:161} INFO - Processing /opt/airflow/dags/docker_job/dbt_model.py took 8.389 seconds
[2022-06-18 00:39:07,926] {processor.py:153} INFO - Started process (PID=10244) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 00:39:07,969] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 00:39:07,970] {logging_mixin.py:115} INFO - [2022-06-18 00:39:07,970] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 00:39:08,451] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 00:39:11,712] {logging_mixin.py:115} INFO - [2022-06-18 00:39:11,699] {dag.py:2379} INFO - Sync 3 DAGs
[2022-06-18 00:39:13,769] {logging_mixin.py:115} INFO - [2022-06-18 00:39:13,741] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-dimensions to 2022-06-17T22:39:13.723524+00:00, run_after=2022-06-18T00:39:13.723524+00:00
[2022-06-18 00:39:13,776] {logging_mixin.py:115} INFO - [2022-06-18 00:39:13,776] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-example to 2022-06-17T22:39:13.776654+00:00, run_after=2022-06-18T00:39:13.776654+00:00
[2022-06-18 00:39:13,799] {logging_mixin.py:115} INFO - [2022-06-18 00:39:13,799] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-objects to 2022-06-17T22:39:13.777046+00:00, run_after=2022-06-18T00:39:13.777046+00:00
[2022-06-18 00:39:48,115] {processor.py:161} INFO - Processing /opt/airflow/dags/docker_job/dbt_model.py took 40.268 seconds
[2022-06-18 00:47:20,397] {processor.py:153} INFO - Started process (PID=10406) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 00:47:20,435] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 00:47:20,464] {logging_mixin.py:115} INFO - [2022-06-18 00:47:20,464] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 00:47:32,135] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 00:49:27,491] {processor.py:164} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3141, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 301, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 755, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 419, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 142, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 247, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 362, in __init__
    self.__connect(first_connect_check=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 605, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 599, in __connect
    connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 578, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 583, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres_source" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 158, in _run_file_processor
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 660, in process_file
    dagbag.sync_to_db()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 615, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 382, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 360, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 193, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 627, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 601, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 68, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 142, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2734, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2821, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1669, in execute
    conn = self._connection_for_bind(bind, close_with_result=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1520, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3095, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 91, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3174, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3145, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2004, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3141, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 301, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 755, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 419, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 142, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 247, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 362, in __init__
    self.__connect(first_connect_check=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 605, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 599, in __connect
    connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 578, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 583, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres_source" to address: Temporary failure in name resolution

(Background on this error at: http://sqlalche.me/e/14/e3q8)
[2022-06-18 01:01:41,105] {processor.py:153} INFO - Started process (PID=10786) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 01:01:41,106] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 01:01:41,107] {logging_mixin.py:115} INFO - [2022-06-18 01:01:41,107] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 01:01:43,929] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 01:06:32,606] {processor.py:153} INFO - Started process (PID=195) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 01:06:32,607] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 01:06:32,607] {logging_mixin.py:115} INFO - [2022-06-18 01:06:32,607] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 01:06:32,613] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 01:06:32,641] {logging_mixin.py:115} INFO - [2022-06-18 01:06:32,641] {dag.py:2379} INFO - Sync 3 DAGs
[2022-06-18 01:06:32,660] {logging_mixin.py:115} INFO - [2022-06-18 01:06:32,659] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-dimensions to 2022-06-17T23:06:32.659723+00:00, run_after=2022-06-18T01:06:32.659723+00:00
[2022-06-18 01:06:32,660] {logging_mixin.py:115} INFO - [2022-06-18 01:06:32,660] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-example to 2022-06-17T23:06:32.660239+00:00, run_after=2022-06-18T01:06:32.660239+00:00
[2022-06-18 01:06:32,660] {logging_mixin.py:115} INFO - [2022-06-18 01:06:32,660] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-objects to 2022-06-17T23:06:32.660468+00:00, run_after=2022-06-18T01:06:32.660468+00:00
[2022-06-18 01:06:32,669] {processor.py:161} INFO - Processing /opt/airflow/dags/docker_job/dbt_model.py took 0.069 seconds
[2022-06-18 01:07:03,481] {processor.py:153} INFO - Started process (PID=442) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 01:07:03,481] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 01:07:03,482] {logging_mixin.py:115} INFO - [2022-06-18 01:07:03,482] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 01:07:03,489] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 01:07:03,518] {logging_mixin.py:115} INFO - [2022-06-18 01:07:03,518] {dag.py:2379} INFO - Sync 3 DAGs
[2022-06-18 01:07:03,537] {logging_mixin.py:115} INFO - [2022-06-18 01:07:03,537] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-dimensions to 2022-06-17T23:07:03.537491+00:00, run_after=2022-06-18T01:07:03.537491+00:00
[2022-06-18 01:07:03,538] {logging_mixin.py:115} INFO - [2022-06-18 01:07:03,538] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-example to 2022-06-17T23:07:03.538092+00:00, run_after=2022-06-18T01:07:03.538092+00:00
[2022-06-18 01:07:03,538] {logging_mixin.py:115} INFO - [2022-06-18 01:07:03,538] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-objects to 2022-06-17T23:07:03.538319+00:00, run_after=2022-06-18T01:07:03.538319+00:00
[2022-06-18 01:07:03,548] {processor.py:161} INFO - Processing /opt/airflow/dags/docker_job/dbt_model.py took 0.070 seconds
[2022-06-18 01:07:34,419] {processor.py:153} INFO - Started process (PID=683) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 01:07:34,420] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 01:07:34,420] {logging_mixin.py:115} INFO - [2022-06-18 01:07:34,420] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 01:07:34,426] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 01:07:34,454] {logging_mixin.py:115} INFO - [2022-06-18 01:07:34,454] {dag.py:2379} INFO - Sync 3 DAGs
[2022-06-18 01:07:34,472] {logging_mixin.py:115} INFO - [2022-06-18 01:07:34,472] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-dimensions to 2022-06-17T23:07:34.472479+00:00, run_after=2022-06-18T01:07:34.472479+00:00
[2022-06-18 01:07:34,473] {logging_mixin.py:115} INFO - [2022-06-18 01:07:34,473] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-example to 2022-06-17T23:07:34.472975+00:00, run_after=2022-06-18T01:07:34.472975+00:00
[2022-06-18 01:07:34,473] {logging_mixin.py:115} INFO - [2022-06-18 01:07:34,473] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-objects to 2022-06-17T23:07:34.473190+00:00, run_after=2022-06-18T01:07:34.473190+00:00
[2022-06-18 01:07:34,482] {processor.py:161} INFO - Processing /opt/airflow/dags/docker_job/dbt_model.py took 0.066 seconds
[2022-06-18 01:08:05,460] {processor.py:153} INFO - Started process (PID=923) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 01:08:05,461] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 01:08:05,461] {logging_mixin.py:115} INFO - [2022-06-18 01:08:05,461] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 01:08:05,468] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 01:08:05,496] {logging_mixin.py:115} INFO - [2022-06-18 01:08:05,496] {dag.py:2379} INFO - Sync 3 DAGs
[2022-06-18 01:08:05,514] {logging_mixin.py:115} INFO - [2022-06-18 01:08:05,514] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-dimensions to 2022-06-17T23:08:05.514635+00:00, run_after=2022-06-18T01:08:05.514635+00:00
[2022-06-18 01:08:05,515] {logging_mixin.py:115} INFO - [2022-06-18 01:08:05,515] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-example to 2022-06-17T23:08:05.515113+00:00, run_after=2022-06-18T01:08:05.515113+00:00
[2022-06-18 01:08:05,515] {logging_mixin.py:115} INFO - [2022-06-18 01:08:05,515] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-objects to 2022-06-17T23:08:05.515330+00:00, run_after=2022-06-18T01:08:05.515330+00:00
[2022-06-18 01:08:05,524] {processor.py:161} INFO - Processing /opt/airflow/dags/docker_job/dbt_model.py took 0.068 seconds
[2022-06-18 01:08:35,682] {processor.py:153} INFO - Started process (PID=1163) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 01:08:35,683] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 01:08:35,683] {logging_mixin.py:115} INFO - [2022-06-18 01:08:35,683] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 01:08:35,690] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 01:08:35,716] {logging_mixin.py:115} INFO - [2022-06-18 01:08:35,716] {dag.py:2379} INFO - Sync 3 DAGs
[2022-06-18 01:08:35,734] {logging_mixin.py:115} INFO - [2022-06-18 01:08:35,734] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-dimensions to 2022-06-17T23:08:35.734098+00:00, run_after=2022-06-18T01:08:35.734098+00:00
[2022-06-18 01:08:35,734] {logging_mixin.py:115} INFO - [2022-06-18 01:08:35,734] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-example to 2022-06-17T23:08:35.734546+00:00, run_after=2022-06-18T01:08:35.734546+00:00
[2022-06-18 01:08:35,734] {logging_mixin.py:115} INFO - [2022-06-18 01:08:35,734] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-objects to 2022-06-17T23:08:35.734751+00:00, run_after=2022-06-18T01:08:35.734751+00:00
[2022-06-18 01:08:35,743] {processor.py:161} INFO - Processing /opt/airflow/dags/docker_job/dbt_model.py took 0.064 seconds
[2022-06-18 01:09:06,750] {processor.py:153} INFO - Started process (PID=1425) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 01:09:06,750] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 01:09:06,751] {logging_mixin.py:115} INFO - [2022-06-18 01:09:06,751] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 01:09:06,758] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 01:09:06,786] {logging_mixin.py:115} INFO - [2022-06-18 01:09:06,786] {dag.py:2379} INFO - Sync 3 DAGs
[2022-06-18 01:09:06,915] {logging_mixin.py:115} INFO - [2022-06-18 01:09:06,915] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-dimensions to 2022-06-17T23:09:06.915251+00:00, run_after=2022-06-18T01:09:06.915251+00:00
[2022-06-18 01:09:06,915] {logging_mixin.py:115} INFO - [2022-06-18 01:09:06,915] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-example to 2022-06-17T23:09:06.915675+00:00, run_after=2022-06-18T01:09:06.915675+00:00
[2022-06-18 01:09:06,916] {logging_mixin.py:115} INFO - [2022-06-18 01:09:06,915] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-objects to 2022-06-17T23:09:06.915885+00:00, run_after=2022-06-18T01:09:06.915885+00:00
[2022-06-18 01:09:06,925] {processor.py:161} INFO - Processing /opt/airflow/dags/docker_job/dbt_model.py took 0.179 seconds
[2022-06-18 01:09:37,390] {processor.py:153} INFO - Started process (PID=1675) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 01:09:37,391] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 01:09:37,391] {logging_mixin.py:115} INFO - [2022-06-18 01:09:37,391] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 01:09:37,404] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 01:09:37,434] {logging_mixin.py:115} INFO - [2022-06-18 01:09:37,434] {dag.py:2379} INFO - Sync 3 DAGs
[2022-06-18 01:09:37,565] {logging_mixin.py:115} INFO - [2022-06-18 01:09:37,565] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-dimensions to 2022-06-17T23:09:37.564829+00:00, run_after=2022-06-18T01:09:37.564829+00:00
[2022-06-18 01:09:37,565] {logging_mixin.py:115} INFO - [2022-06-18 01:09:37,565] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-example to 2022-06-17T23:09:37.565251+00:00, run_after=2022-06-18T01:09:37.565251+00:00
[2022-06-18 01:09:37,565] {logging_mixin.py:115} INFO - [2022-06-18 01:09:37,565] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-objects to 2022-06-17T23:09:37.565458+00:00, run_after=2022-06-18T01:09:37.565458+00:00
[2022-06-18 01:09:37,573] {processor.py:161} INFO - Processing /opt/airflow/dags/docker_job/dbt_model.py took 0.187 seconds
[2022-06-18 01:10:07,711] {processor.py:153} INFO - Started process (PID=1919) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 01:10:07,711] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 01:10:07,712] {logging_mixin.py:115} INFO - [2022-06-18 01:10:07,712] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 01:10:07,719] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 01:10:07,845] {logging_mixin.py:115} INFO - [2022-06-18 01:10:07,845] {dag.py:2379} INFO - Sync 3 DAGs
[2022-06-18 01:10:07,860] {logging_mixin.py:115} INFO - [2022-06-18 01:10:07,860] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-dimensions to 2022-06-17T23:10:07.859997+00:00, run_after=2022-06-18T01:10:07.859997+00:00
[2022-06-18 01:10:07,860] {logging_mixin.py:115} INFO - [2022-06-18 01:10:07,860] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-example to 2022-06-17T23:10:07.860480+00:00, run_after=2022-06-18T01:10:07.860480+00:00
[2022-06-18 01:10:07,860] {logging_mixin.py:115} INFO - [2022-06-18 01:10:07,860] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-objects to 2022-06-17T23:10:07.860682+00:00, run_after=2022-06-18T01:10:07.860682+00:00
[2022-06-18 01:10:07,868] {processor.py:161} INFO - Processing /opt/airflow/dags/docker_job/dbt_model.py took 0.160 seconds
[2022-06-18 01:10:38,884] {processor.py:153} INFO - Started process (PID=2159) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 01:10:38,885] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 01:10:38,885] {logging_mixin.py:115} INFO - [2022-06-18 01:10:38,885] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 01:10:38,997] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 01:10:39,016] {logging_mixin.py:115} INFO - [2022-06-18 01:10:39,016] {dag.py:2379} INFO - Sync 3 DAGs
[2022-06-18 01:10:39,030] {logging_mixin.py:115} INFO - [2022-06-18 01:10:39,030] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-dimensions to 2022-06-17T23:10:39.030643+00:00, run_after=2022-06-18T01:10:39.030643+00:00
[2022-06-18 01:10:39,031] {logging_mixin.py:115} INFO - [2022-06-18 01:10:39,031] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-example to 2022-06-17T23:10:39.031019+00:00, run_after=2022-06-18T01:10:39.031019+00:00
[2022-06-18 01:10:39,031] {logging_mixin.py:115} INFO - [2022-06-18 01:10:39,031] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-objects to 2022-06-17T23:10:39.031234+00:00, run_after=2022-06-18T01:10:39.031234+00:00
[2022-06-18 01:10:39,038] {processor.py:161} INFO - Processing /opt/airflow/dags/docker_job/dbt_model.py took 0.157 seconds
[2022-06-18 08:47:51,343] {processor.py:153} INFO - Started process (PID=2416) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 08:47:51,347] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 08:47:51,347] {logging_mixin.py:115} INFO - [2022-06-18 08:47:51,347] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 08:47:52,687] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 08:47:53,516] {logging_mixin.py:115} INFO - [2022-06-18 08:47:53,516] {dag.py:2379} INFO - Sync 3 DAGs
[2022-06-18 08:47:53,656] {logging_mixin.py:115} INFO - [2022-06-18 08:47:53,656] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-dimensions to 2022-06-18T06:47:53.655911+00:00, run_after=2022-06-18T08:47:53.655911+00:00
[2022-06-18 08:47:53,656] {logging_mixin.py:115} INFO - [2022-06-18 08:47:53,656] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-example to 2022-06-18T06:47:53.656353+00:00, run_after=2022-06-18T08:47:53.656353+00:00
[2022-06-18 08:47:53,656] {logging_mixin.py:115} INFO - [2022-06-18 08:47:53,656] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-objects to 2022-06-18T06:47:53.656564+00:00, run_after=2022-06-18T08:47:53.656564+00:00
[2022-06-18 08:47:53,874] {processor.py:161} INFO - Processing /opt/airflow/dags/docker_job/dbt_model.py took 2.534 seconds
[2022-06-18 08:51:57,597] {processor.py:153} INFO - Started process (PID=2707) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 08:51:57,612] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 08:51:57,612] {logging_mixin.py:115} INFO - [2022-06-18 08:51:57,612] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 08:51:57,906] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 08:52:00,429] {logging_mixin.py:115} INFO - [2022-06-18 08:52:00,429] {dag.py:2379} INFO - Sync 3 DAGs
[2022-06-18 08:52:01,112] {logging_mixin.py:115} INFO - [2022-06-18 08:52:01,112] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-dimensions to 2022-06-18T06:52:01.080562+00:00, run_after=2022-06-18T08:52:01.080562+00:00
[2022-06-18 08:52:01,117] {logging_mixin.py:115} INFO - [2022-06-18 08:52:01,117] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-example to 2022-06-18T06:52:01.117477+00:00, run_after=2022-06-18T08:52:01.117477+00:00
[2022-06-18 08:52:01,117] {logging_mixin.py:115} INFO - [2022-06-18 08:52:01,117] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-objects to 2022-06-18T06:52:01.117842+00:00, run_after=2022-06-18T08:52:01.117842+00:00
[2022-06-18 08:52:03,529] {processor.py:161} INFO - Processing /opt/airflow/dags/docker_job/dbt_model.py took 5.937 seconds
[2022-06-18 08:57:08,363] {processor.py:153} INFO - Started process (PID=2752) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 08:57:08,372] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 08:57:08,373] {logging_mixin.py:115} INFO - [2022-06-18 08:57:08,373] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 08:57:08,974] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 08:57:09,752] {logging_mixin.py:115} INFO - [2022-06-18 08:57:09,751] {dag.py:2379} INFO - Sync 3 DAGs
[2022-06-18 08:57:09,873] {logging_mixin.py:115} INFO - [2022-06-18 08:57:09,873] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-dimensions to 2022-06-18T06:57:09.872895+00:00, run_after=2022-06-18T08:57:09.872895+00:00
[2022-06-18 08:57:09,873] {logging_mixin.py:115} INFO - [2022-06-18 08:57:09,873] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-example to 2022-06-18T06:57:09.873664+00:00, run_after=2022-06-18T08:57:09.873664+00:00
[2022-06-18 08:57:09,876] {logging_mixin.py:115} INFO - [2022-06-18 08:57:09,874] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-objects to 2022-06-18T06:57:09.874009+00:00, run_after=2022-06-18T08:57:09.874009+00:00
[2022-06-18 08:57:10,077] {processor.py:161} INFO - Processing /opt/airflow/dags/docker_job/dbt_model.py took 1.726 seconds
[2022-06-18 09:01:52,464] {processor.py:153} INFO - Started process (PID=2897) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 09:01:52,533] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 09:01:52,533] {logging_mixin.py:115} INFO - [2022-06-18 09:01:52,533] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 09:01:52,723] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 09:01:53,350] {logging_mixin.py:115} INFO - [2022-06-18 09:01:53,349] {dag.py:2379} INFO - Sync 3 DAGs
[2022-06-18 09:01:53,649] {logging_mixin.py:115} INFO - [2022-06-18 09:01:53,649] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-dimensions to 2022-06-18T07:01:53.649050+00:00, run_after=2022-06-18T09:01:53.649050+00:00
[2022-06-18 09:01:53,650] {logging_mixin.py:115} INFO - [2022-06-18 09:01:53,650] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-example to 2022-06-18T07:01:53.649952+00:00, run_after=2022-06-18T09:01:53.649952+00:00
[2022-06-18 09:01:53,663] {logging_mixin.py:115} INFO - [2022-06-18 09:01:53,651] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-objects to 2022-06-18T07:01:53.650680+00:00, run_after=2022-06-18T09:01:53.650680+00:00
[2022-06-18 09:01:53,911] {processor.py:161} INFO - Processing /opt/airflow/dags/docker_job/dbt_model.py took 1.534 seconds
[2022-06-18 09:04:45,830] {processor.py:153} INFO - Started process (PID=3018) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 09:04:46,670] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 09:04:47,323] {logging_mixin.py:115} INFO - [2022-06-18 09:04:47,323] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 09:05:14,131] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 09:05:31,504] {logging_mixin.py:115} INFO - [2022-06-18 09:05:31,504] {dag.py:2379} INFO - Sync 3 DAGs
[2022-06-18 09:05:31,879] {logging_mixin.py:115} INFO - [2022-06-18 09:05:31,879] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-dimensions to 2022-06-18T07:05:31.878758+00:00, run_after=2022-06-18T09:05:31.878758+00:00
[2022-06-18 09:05:31,879] {logging_mixin.py:115} INFO - [2022-06-18 09:05:31,879] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-example to 2022-06-18T07:05:31.879505+00:00, run_after=2022-06-18T09:05:31.879505+00:00
[2022-06-18 09:05:31,879] {logging_mixin.py:115} INFO - [2022-06-18 09:05:31,879] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-objects to 2022-06-18T07:05:31.879811+00:00, run_after=2022-06-18T09:05:31.879811+00:00
[2022-06-18 09:05:31,941] {processor.py:161} INFO - Processing /opt/airflow/dags/docker_job/dbt_model.py took 46.464 seconds
[2022-06-18 09:07:35,855] {processor.py:153} INFO - Started process (PID=3098) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 09:07:35,861] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 09:07:35,861] {logging_mixin.py:115} INFO - [2022-06-18 09:07:35,861] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 09:07:35,896] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 09:08:47,732] {logging_mixin.py:115} INFO - [2022-06-18 09:08:47,659] {dag.py:2379} INFO - Sync 3 DAGs
[2022-06-18 09:08:47,808] {logging_mixin.py:115} INFO - [2022-06-18 09:08:47,808] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-dimensions to 2022-06-18T07:08:47.805004+00:00, run_after=2022-06-18T09:08:47.805004+00:00
[2022-06-18 09:08:47,808] {logging_mixin.py:115} INFO - [2022-06-18 09:08:47,808] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-example to 2022-06-18T07:08:47.808583+00:00, run_after=2022-06-18T09:08:47.808583+00:00
[2022-06-18 09:08:47,808] {logging_mixin.py:115} INFO - [2022-06-18 09:08:47,808] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-objects to 2022-06-18T07:08:47.808824+00:00, run_after=2022-06-18T09:08:47.808824+00:00
[2022-06-18 09:08:47,895] {processor.py:161} INFO - Processing /opt/airflow/dags/docker_job/dbt_model.py took 72.177 seconds
[2022-06-18 09:11:01,116] {processor.py:153} INFO - Started process (PID=3262) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 09:11:01,117] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 09:11:01,117] {logging_mixin.py:115} INFO - [2022-06-18 09:11:01,117] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 09:11:34,551] {logging_mixin.py:115} INFO - [2022-06-18 09:11:34,156] {timeout.py:67} ERROR - Process timed out, PID: 3262
[2022-06-18 09:11:38,657] {logging_mixin.py:115} INFO - [2022-06-18 09:11:34,569] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/docker_job/dbt_model.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/docker_job/dbt_model.py", line 74, in <module>
    default_args=default_args)
  File "/opt/airflow/dags/docker_job/dbt_model.py", line 40, in create_dag
    && dbt run --models {dbt_model} --profiles-dir /tmp/{dbt_model}/dbt/"
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 364, in apply_defaults
    task_default_args=kwargs.pop("default_args", None),
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 154, in get_merged_defaults
    args, params = _get_parent_defaults(dag, task_group)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 140, in _get_parent_defaults
    dag_params = copy.deepcopy(dag.params)
  File "/usr/local/lib/python3.7/copy.py", line 161, in deepcopy
    y = copier(memo)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/param.py", line 136, in __deepcopy__
    return ParamsDict(copy.deepcopy(self.__dict, memo), self.suppress_exception)
  File "/usr/local/lib/python3.7/typing.py", line 818, in __new__
    if super().__new__ is object.__new__ and cls.__init__ is not object.__init__:
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/docker_job/dbt_model.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.2/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.2/best-practices.html#reducing-dag-complexity, PID: 3262
[2022-06-18 09:11:38,816] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 09:15:11,941] {processor.py:153} INFO - Started process (PID=3300) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 09:15:11,943] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 09:15:11,944] {logging_mixin.py:115} INFO - [2022-06-18 09:15:11,943] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 09:15:12,552] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 09:16:11,425] {logging_mixin.py:115} INFO - [2022-06-18 09:16:11,425] {dag.py:2379} INFO - Sync 3 DAGs
[2022-06-18 09:19:30,261] {processor.py:153} INFO - Started process (PID=3361) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 09:19:30,262] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 09:19:30,263] {logging_mixin.py:115} INFO - [2022-06-18 09:19:30,262] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 09:19:30,355] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 09:19:30,526] {logging_mixin.py:115} INFO - [2022-06-18 09:19:30,526] {dag.py:2379} INFO - Sync 3 DAGs
[2022-06-18 09:19:30,572] {logging_mixin.py:115} INFO - [2022-06-18 09:19:30,571] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-dimensions to 2022-06-18T07:19:30.571326+00:00, run_after=2022-06-18T09:19:30.571326+00:00
[2022-06-18 09:19:30,572] {logging_mixin.py:115} INFO - [2022-06-18 09:19:30,572] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-example to 2022-06-18T07:19:30.572214+00:00, run_after=2022-06-18T09:19:30.572214+00:00
[2022-06-18 09:19:30,572] {logging_mixin.py:115} INFO - [2022-06-18 09:19:30,572] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-objects to 2022-06-18T07:19:30.572548+00:00, run_after=2022-06-18T09:19:30.572548+00:00
[2022-06-18 09:19:30,607] {processor.py:161} INFO - Processing /opt/airflow/dags/docker_job/dbt_model.py took 0.358 seconds
[2022-06-18 09:21:33,441] {processor.py:153} INFO - Started process (PID=3614) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 09:21:33,493] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 09:21:33,494] {logging_mixin.py:115} INFO - [2022-06-18 09:21:33,493] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 09:21:33,733] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 09:21:34,070] {logging_mixin.py:115} INFO - [2022-06-18 09:21:34,070] {dag.py:2379} INFO - Sync 3 DAGs
[2022-06-18 09:21:34,287] {logging_mixin.py:115} INFO - [2022-06-18 09:21:34,287] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-dimensions to 2022-06-18T07:21:34.286642+00:00, run_after=2022-06-18T09:21:34.286642+00:00
[2022-06-18 09:21:34,288] {logging_mixin.py:115} INFO - [2022-06-18 09:21:34,288] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-example to 2022-06-18T07:21:34.288157+00:00, run_after=2022-06-18T09:21:34.288157+00:00
[2022-06-18 09:21:34,288] {logging_mixin.py:115} INFO - [2022-06-18 09:21:34,288] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-objects to 2022-06-18T07:21:34.288455+00:00, run_after=2022-06-18T09:21:34.288455+00:00
[2022-06-18 09:21:34,491] {processor.py:161} INFO - Processing /opt/airflow/dags/docker_job/dbt_model.py took 1.074 seconds
[2022-06-18 09:23:41,674] {processor.py:153} INFO - Started process (PID=3646) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 09:23:41,706] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 09:23:41,706] {logging_mixin.py:115} INFO - [2022-06-18 09:23:41,706] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 09:23:42,004] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 09:23:42,540] {logging_mixin.py:115} INFO - [2022-06-18 09:23:42,540] {dag.py:2379} INFO - Sync 3 DAGs
[2022-06-18 09:23:42,964] {logging_mixin.py:115} INFO - [2022-06-18 09:23:42,963] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-dimensions to 2022-06-18T07:23:42.930122+00:00, run_after=2022-06-18T09:23:42.930122+00:00
[2022-06-18 09:23:42,964] {logging_mixin.py:115} INFO - [2022-06-18 09:23:42,964] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-example to 2022-06-18T07:23:42.964285+00:00, run_after=2022-06-18T09:23:42.964285+00:00
[2022-06-18 09:23:42,964] {logging_mixin.py:115} INFO - [2022-06-18 09:23:42,964] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-objects to 2022-06-18T07:23:42.964848+00:00, run_after=2022-06-18T09:23:42.964848+00:00
[2022-06-18 09:23:43,204] {processor.py:161} INFO - Processing /opt/airflow/dags/docker_job/dbt_model.py took 1.550 seconds
[2022-06-18 09:28:10,648] {processor.py:153} INFO - Started process (PID=3698) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 09:28:10,652] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 09:28:10,653] {logging_mixin.py:115} INFO - [2022-06-18 09:28:10,653] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 09:29:07,561] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 09:33:12,129] {processor.py:153} INFO - Started process (PID=3847) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 09:33:12,351] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 09:33:12,351] {logging_mixin.py:115} INFO - [2022-06-18 09:33:12,351] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 09:33:13,261] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 09:33:17,468] {logging_mixin.py:115} INFO - [2022-06-18 09:33:17,468] {dag.py:2379} INFO - Sync 3 DAGs
[2022-06-18 09:33:18,506] {logging_mixin.py:115} INFO - [2022-06-18 09:33:18,497] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-dimensions to 2022-06-18T07:33:18.467498+00:00, run_after=2022-06-18T09:33:18.467498+00:00
[2022-06-18 09:33:18,692] {logging_mixin.py:115} INFO - [2022-06-18 09:33:18,692] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-example to 2022-06-18T07:33:18.690344+00:00, run_after=2022-06-18T09:33:18.690344+00:00
[2022-06-18 09:33:18,693] {logging_mixin.py:115} INFO - [2022-06-18 09:33:18,693] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-objects to 2022-06-18T07:33:18.693165+00:00, run_after=2022-06-18T09:33:18.693165+00:00
[2022-06-18 09:33:20,583] {processor.py:161} INFO - Processing /opt/airflow/dags/docker_job/dbt_model.py took 8.580 seconds
[2022-06-18 09:37:38,942] {processor.py:153} INFO - Started process (PID=3935) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 09:37:38,993] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 09:37:38,994] {logging_mixin.py:115} INFO - [2022-06-18 09:37:38,994] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 09:37:39,492] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 09:44:49,695] {processor.py:153} INFO - Started process (PID=4037) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 09:44:49,731] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 09:44:49,734] {logging_mixin.py:115} INFO - [2022-06-18 09:44:49,734] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 09:44:50,042] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 09:44:51,242] {logging_mixin.py:115} INFO - [2022-06-18 09:44:51,241] {dag.py:2379} INFO - Sync 3 DAGs
[2022-06-18 09:44:51,310] {logging_mixin.py:115} INFO - [2022-06-18 09:44:51,310] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-dimensions to 2022-06-18T07:44:51.310445+00:00, run_after=2022-06-18T09:44:51.310445+00:00
[2022-06-18 09:44:51,311] {logging_mixin.py:115} INFO - [2022-06-18 09:44:51,311] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-example to 2022-06-18T07:44:51.311207+00:00, run_after=2022-06-18T09:44:51.311207+00:00
[2022-06-18 09:44:51,311] {logging_mixin.py:115} INFO - [2022-06-18 09:44:51,311] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-objects to 2022-06-18T07:44:51.311487+00:00, run_after=2022-06-18T09:44:51.311487+00:00
[2022-06-18 09:44:51,366] {processor.py:161} INFO - Processing /opt/airflow/dags/docker_job/dbt_model.py took 1.674 seconds
[2022-06-18 09:47:45,929] {processor.py:153} INFO - Started process (PID=4163) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 09:47:46,068] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 09:47:46,194] {logging_mixin.py:115} INFO - [2022-06-18 09:47:46,069] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 09:47:47,365] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 09:54:15,346] {processor.py:153} INFO - Started process (PID=4281) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 09:54:15,414] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 09:54:15,414] {logging_mixin.py:115} INFO - [2022-06-18 09:54:15,414] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 09:54:18,745] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 09:55:21,543] {logging_mixin.py:115} INFO - [2022-06-18 09:55:21,542] {dag.py:2379} INFO - Sync 3 DAGs
[2022-06-18 10:01:19,939] {processor.py:153} INFO - Started process (PID=4405) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 10:01:19,943] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 10:01:19,944] {logging_mixin.py:115} INFO - [2022-06-18 10:01:19,944] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 10:01:21,558] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 10:01:35,879] {logging_mixin.py:115} INFO - [2022-06-18 10:01:35,878] {dag.py:2379} INFO - Sync 3 DAGs
[2022-06-18 10:01:48,153] {logging_mixin.py:115} INFO - [2022-06-18 10:01:48,022] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-dimensions to 2022-06-18T08:01:48.021716+00:00, run_after=2022-06-18T10:01:48.021716+00:00
[2022-06-18 10:01:55,182] {logging_mixin.py:115} INFO - [2022-06-18 10:01:52,005] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-example to 2022-06-18T08:01:48.361090+00:00, run_after=2022-06-18T10:01:48.361090+00:00
[2022-06-18 10:01:56,563] {logging_mixin.py:115} INFO - [2022-06-18 10:01:56,096] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-objects to 2022-06-18T08:01:55.506217+00:00, run_after=2022-06-18T10:01:55.506217+00:00
[2022-06-18 10:10:42,500] {processor.py:153} INFO - Started process (PID=4552) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 10:10:42,538] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 10:10:42,538] {logging_mixin.py:115} INFO - [2022-06-18 10:10:42,538] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 10:10:42,922] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 10:10:50,230] {logging_mixin.py:115} INFO - [2022-06-18 10:10:50,228] {dag.py:2379} INFO - Sync 3 DAGs
[2022-06-18 10:17:31,557] {processor.py:153} INFO - Started process (PID=4635) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 10:17:31,575] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 10:17:31,576] {logging_mixin.py:115} INFO - [2022-06-18 10:17:31,576] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 10:17:32,266] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 10:31:33,175] {processor.py:153} INFO - Started process (PID=4821) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 10:31:33,375] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 10:31:33,514] {logging_mixin.py:115} INFO - [2022-06-18 10:31:33,495] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 10:31:59,760] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 10:36:14,662] {processor.py:153} INFO - Started process (PID=4902) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 10:36:14,676] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 10:36:14,677] {logging_mixin.py:115} INFO - [2022-06-18 10:36:14,677] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 10:36:15,431] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 10:36:42,091] {logging_mixin.py:115} INFO - [2022-06-18 10:36:42,063] {dag.py:2379} INFO - Sync 3 DAGs
[2022-06-18 10:36:43,845] {logging_mixin.py:115} INFO - [2022-06-18 10:36:43,723] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-dimensions to 2022-06-18T08:36:43.686849+00:00, run_after=2022-06-18T10:36:43.686849+00:00
[2022-06-18 10:36:43,855] {logging_mixin.py:115} INFO - [2022-06-18 10:36:43,854] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-example to 2022-06-18T08:36:43.849038+00:00, run_after=2022-06-18T10:36:43.849038+00:00
[2022-06-18 10:36:43,855] {logging_mixin.py:115} INFO - [2022-06-18 10:36:43,855] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-objects to 2022-06-18T08:36:43.855396+00:00, run_after=2022-06-18T10:36:43.855396+00:00
[2022-06-18 10:38:17,706] {processor.py:161} INFO - Processing /opt/airflow/dags/docker_job/dbt_model.py took 123.511 seconds
[2022-06-18 12:32:28,937] {processor.py:153} INFO - Started process (PID=5154) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 12:32:28,946] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 12:32:29,087] {logging_mixin.py:115} INFO - [2022-06-18 12:32:29,087] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 12:32:30,000] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 12:37:57,058] {processor.py:153} INFO - Started process (PID=5276) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 12:37:57,060] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 12:37:57,063] {logging_mixin.py:115} INFO - [2022-06-18 12:37:57,063] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 12:37:58,883] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 12:46:05,171] {processor.py:153} INFO - Started process (PID=5397) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 12:46:05,188] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 12:46:05,189] {logging_mixin.py:115} INFO - [2022-06-18 12:46:05,188] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 12:46:06,113] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 12:52:21,192] {processor.py:153} INFO - Started process (PID=231) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 12:52:21,198] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 12:52:21,199] {logging_mixin.py:115} INFO - [2022-06-18 12:52:21,199] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 12:52:21,210] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 12:52:21,428] {logging_mixin.py:115} INFO - [2022-06-18 12:52:21,428] {dag.py:2379} INFO - Sync 3 DAGs
[2022-06-18 12:52:21,563] {logging_mixin.py:115} INFO - [2022-06-18 12:52:21,563] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-dimensions to 2022-06-18T10:52:21.562186+00:00, run_after=2022-06-18T12:52:21.562186+00:00
[2022-06-18 12:52:21,643] {logging_mixin.py:115} INFO - [2022-06-18 12:52:21,642] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-example to 2022-06-18T10:52:21.642206+00:00, run_after=2022-06-18T12:52:21.642206+00:00
[2022-06-18 12:52:21,644] {logging_mixin.py:115} INFO - [2022-06-18 12:52:21,644] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-objects to 2022-06-18T10:52:21.644236+00:00, run_after=2022-06-18T12:52:21.644236+00:00
[2022-06-18 12:52:21,856] {processor.py:161} INFO - Processing /opt/airflow/dags/docker_job/dbt_model.py took 0.681 seconds
[2022-06-18 12:57:39,870] {processor.py:153} INFO - Started process (PID=353) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 12:57:39,882] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 12:57:39,882] {logging_mixin.py:115} INFO - [2022-06-18 12:57:39,882] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 12:57:40,544] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 13:12:00,641] {processor.py:153} INFO - Started process (PID=724) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 13:12:00,646] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 13:12:00,646] {logging_mixin.py:115} INFO - [2022-06-18 13:12:00,646] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 13:12:00,894] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 13:12:02,191] {logging_mixin.py:115} INFO - [2022-06-18 13:12:02,189] {dag.py:2379} INFO - Sync 3 DAGs
[2022-06-18 13:13:43,741] {logging_mixin.py:115} INFO - [2022-06-18 13:13:43,489] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-dimensions to 2022-06-18T11:13:43.407736+00:00, run_after=2022-06-18T13:13:43.407736+00:00
[2022-06-18 13:13:43,909] {logging_mixin.py:115} INFO - [2022-06-18 13:13:43,908] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-example to 2022-06-18T11:13:43.860659+00:00, run_after=2022-06-18T13:13:43.860659+00:00
[2022-06-18 13:13:43,914] {logging_mixin.py:115} INFO - [2022-06-18 13:13:43,914] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-objects to 2022-06-18T11:13:43.913637+00:00, run_after=2022-06-18T13:13:43.913637+00:00
[2022-06-18 13:52:36,358] {processor.py:153} INFO - Started process (PID=1161) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 13:52:36,360] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 13:52:36,363] {logging_mixin.py:115} INFO - [2022-06-18 13:52:36,363] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 13:52:36,736] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 13:52:41,297] {logging_mixin.py:115} INFO - [2022-06-18 13:52:41,297] {dag.py:2379} INFO - Sync 3 DAGs
[2022-06-18 13:52:42,262] {logging_mixin.py:115} INFO - [2022-06-18 13:52:42,262] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-dimensions to 2022-06-18T11:52:42.262398+00:00, run_after=2022-06-18T13:52:42.262398+00:00
[2022-06-18 13:52:42,283] {logging_mixin.py:115} INFO - [2022-06-18 13:52:42,283] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-example to 2022-06-18T11:52:42.283536+00:00, run_after=2022-06-18T13:52:42.283536+00:00
[2022-06-18 13:52:42,361] {logging_mixin.py:115} INFO - [2022-06-18 13:52:42,361] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-objects to 2022-06-18T11:52:42.283905+00:00, run_after=2022-06-18T13:52:42.283905+00:00
[2022-06-18 13:52:53,090] {processor.py:161} INFO - Processing /opt/airflow/dags/docker_job/dbt_model.py took 16.874 seconds
[2022-06-18 14:23:34,283] {processor.py:153} INFO - Started process (PID=1515) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 14:23:34,288] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 14:23:34,289] {logging_mixin.py:115} INFO - [2022-06-18 14:23:34,289] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 14:23:42,761] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 14:26:16,095] {logging_mixin.py:115} INFO - [2022-06-18 14:26:16,095] {dag.py:2379} INFO - Sync 3 DAGs
[2022-06-18 14:36:05,110] {processor.py:153} INFO - Started process (PID=1650) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 14:36:05,113] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 14:36:05,113] {logging_mixin.py:115} INFO - [2022-06-18 14:36:05,113] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 14:36:05,792] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 14:37:03,541] {logging_mixin.py:115} INFO - [2022-06-18 14:37:03,541] {dag.py:2379} INFO - Sync 3 DAGs
[2022-06-18 14:48:24,556] {processor.py:153} INFO - Started process (PID=1800) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 14:48:24,716] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 14:48:24,716] {logging_mixin.py:115} INFO - [2022-06-18 14:48:24,716] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 14:48:25,390] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 14:48:59,234] {logging_mixin.py:115} INFO - [2022-06-18 14:48:59,234] {dag.py:2379} INFO - Sync 3 DAGs
[2022-06-18 14:49:00,250] {logging_mixin.py:115} INFO - [2022-06-18 14:49:00,249] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-dimensions to 2022-06-18T12:49:00.200985+00:00, run_after=2022-06-18T14:49:00.200985+00:00
[2022-06-18 14:49:00,264] {logging_mixin.py:115} INFO - [2022-06-18 14:49:00,264] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-example to 2022-06-18T12:49:00.264152+00:00, run_after=2022-06-18T14:49:00.264152+00:00
[2022-06-18 14:49:00,266] {logging_mixin.py:115} INFO - [2022-06-18 14:49:00,266] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-objects to 2022-06-18T12:49:00.265934+00:00, run_after=2022-06-18T14:49:00.265934+00:00
[2022-06-18 14:49:00,891] {processor.py:161} INFO - Processing /opt/airflow/dags/docker_job/dbt_model.py took 36.532 seconds
[2022-06-18 14:59:54,803] {processor.py:153} INFO - Started process (PID=83) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 14:59:54,808] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 14:59:54,809] {logging_mixin.py:115} INFO - [2022-06-18 14:59:54,809] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 14:59:55,506] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 14:59:57,286] {logging_mixin.py:115} INFO - [2022-06-18 14:59:57,286] {dag.py:2379} INFO - Sync 3 DAGs
[2022-06-18 14:59:58,817] {logging_mixin.py:115} INFO - [2022-06-18 14:59:58,816] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-dimensions to 2022-06-18T12:59:58.653587+00:00, run_after=2022-06-18T14:59:58.653587+00:00
[2022-06-18 14:59:58,824] {logging_mixin.py:115} INFO - [2022-06-18 14:59:58,823] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-example to 2022-06-18T12:59:58.823621+00:00, run_after=2022-06-18T14:59:58.823621+00:00
[2022-06-18 14:59:58,824] {logging_mixin.py:115} INFO - [2022-06-18 14:59:58,824] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-objects to 2022-06-18T12:59:58.824611+00:00, run_after=2022-06-18T14:59:58.824611+00:00
[2022-06-18 15:00:00,809] {processor.py:161} INFO - Processing /opt/airflow/dags/docker_job/dbt_model.py took 6.014 seconds
[2022-06-18 15:06:05,322] {processor.py:153} INFO - Started process (PID=129) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 15:06:05,726] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 15:06:05,726] {logging_mixin.py:115} INFO - [2022-06-18 15:06:05,726] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 15:06:06,345] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 15:06:25,998] {logging_mixin.py:115} INFO - [2022-06-18 15:06:25,998] {dag.py:2379} INFO - Sync 3 DAGs
[2022-06-18 15:09:48,866] {logging_mixin.py:115} INFO - [2022-06-18 15:09:48,851] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-dimensions to 2022-06-18T13:09:43.381939+00:00, run_after=2022-06-18T15:09:43.381939+00:00
[2022-06-18 15:09:48,867] {logging_mixin.py:115} INFO - [2022-06-18 15:09:48,867] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-example to 2022-06-18T13:09:48.867163+00:00, run_after=2022-06-18T15:09:48.867163+00:00
[2022-06-18 15:09:48,867] {logging_mixin.py:115} INFO - [2022-06-18 15:09:48,867] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-objects to 2022-06-18T13:09:48.867489+00:00, run_after=2022-06-18T15:09:48.867489+00:00
[2022-06-18 15:24:49,701] {processor.py:153} INFO - Started process (PID=233) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 15:24:49,794] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 15:24:50,032] {logging_mixin.py:115} INFO - [2022-06-18 15:24:50,030] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 15:24:52,503] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 15:37:33,923] {logging_mixin.py:115} INFO - [2022-06-18 15:37:33,489] {dag.py:2379} INFO - Sync 3 DAGs
[2022-06-18 15:38:25,440] {logging_mixin.py:115} INFO - [2022-06-18 15:38:25,103] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-dimensions to 2022-06-18T13:38:23.263837+00:00, run_after=2022-06-18T15:38:23.263837+00:00
[2022-06-18 15:38:26,439] {logging_mixin.py:115} INFO - [2022-06-18 15:38:26,414] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-example to 2022-06-18T13:38:26.388032+00:00, run_after=2022-06-18T15:38:26.388032+00:00
[2022-06-18 15:38:26,441] {logging_mixin.py:115} INFO - [2022-06-18 15:38:26,441] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-objects to 2022-06-18T13:38:26.441404+00:00, run_after=2022-06-18T15:38:26.441404+00:00
[2022-06-18 15:38:57,168] {processor.py:161} INFO - Processing /opt/airflow/dags/docker_job/dbt_model.py took 848.578 seconds
[2022-06-18 15:49:00,078] {processor.py:153} INFO - Started process (PID=313) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 15:49:00,095] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 15:49:00,095] {logging_mixin.py:115} INFO - [2022-06-18 15:49:00,095] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 15:49:00,670] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 15:59:46,590] {processor.py:153} INFO - Started process (PID=384) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 15:59:46,663] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 15:59:46,686] {logging_mixin.py:115} INFO - [2022-06-18 15:59:46,664] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 15:59:47,712] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 16:10:47,573] {processor.py:153} INFO - Started process (PID=406) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 16:10:47,579] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 16:10:47,596] {logging_mixin.py:115} INFO - [2022-06-18 16:10:47,596] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 16:10:48,195] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 16:10:55,743] {logging_mixin.py:115} INFO - [2022-06-18 16:10:55,728] {dag.py:2379} INFO - Sync 3 DAGs
[2022-06-18 16:11:03,364] {logging_mixin.py:115} INFO - [2022-06-18 16:11:02,924] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-dimensions to 2022-06-18T14:11:02.114883+00:00, run_after=2022-06-18T16:11:02.114883+00:00
[2022-06-18 16:11:04,188] {logging_mixin.py:115} INFO - [2022-06-18 16:11:03,827] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-example to 2022-06-18T14:11:03.628932+00:00, run_after=2022-06-18T16:11:03.628932+00:00
[2022-06-18 16:11:04,573] {logging_mixin.py:115} INFO - [2022-06-18 16:11:04,567] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-objects to 2022-06-18T14:11:04.530660+00:00, run_after=2022-06-18T16:11:04.530660+00:00
[2022-06-18 16:19:43,450] {processor.py:153} INFO - Started process (PID=444) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 16:19:43,604] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 16:19:44,255] {logging_mixin.py:115} INFO - [2022-06-18 16:19:44,070] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 16:19:46,788] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 16:29:05,503] {processor.py:153} INFO - Started process (PID=486) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 16:29:05,854] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 16:29:06,151] {logging_mixin.py:115} INFO - [2022-06-18 16:29:06,151] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 16:29:08,235] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 16:37:18,509] {processor.py:153} INFO - Started process (PID=507) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 16:37:18,579] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 16:37:18,579] {logging_mixin.py:115} INFO - [2022-06-18 16:37:18,579] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 16:37:21,229] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 16:44:28,044] {processor.py:153} INFO - Started process (PID=536) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 16:44:28,111] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 16:44:28,499] {logging_mixin.py:115} INFO - [2022-06-18 16:44:28,279] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 16:44:38,950] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 16:46:15,804] {processor.py:164} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3141, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 301, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 755, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 419, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 142, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 247, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 362, in __init__
    self.__connect(first_connect_check=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 605, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 599, in __connect
    connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 578, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 583, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres_source" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 158, in _run_file_processor
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 660, in process_file
    dagbag.sync_to_db()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 615, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 382, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 360, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 193, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 627, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 601, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 68, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 142, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2734, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2821, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1669, in execute
    conn = self._connection_for_bind(bind, close_with_result=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1520, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3095, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 91, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3174, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3145, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2004, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3141, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 301, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 755, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 419, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 142, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 247, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 362, in __init__
    self.__connect(first_connect_check=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 605, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 599, in __connect
    connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 578, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 583, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres_source" to address: Temporary failure in name resolution

(Background on this error at: http://sqlalche.me/e/14/e3q8)
[2022-06-18 16:48:50,333] {processor.py:153} INFO - Started process (PID=560) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 16:48:50,382] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 16:48:50,382] {logging_mixin.py:115} INFO - [2022-06-18 16:48:50,382] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 16:48:52,426] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 16:56:08,290] {processor.py:153} INFO - Started process (PID=568) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 16:56:08,351] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 16:56:08,452] {logging_mixin.py:115} INFO - [2022-06-18 16:56:08,451] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 16:56:11,045] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 16:57:46,146] {processor.py:164} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3141, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 301, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 755, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 419, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 142, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 247, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 362, in __init__
    self.__connect(first_connect_check=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 605, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 599, in __connect
    connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 578, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 583, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres_source" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 158, in _run_file_processor
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 660, in process_file
    dagbag.sync_to_db()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 615, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 382, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 360, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 193, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 627, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 601, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 68, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 142, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2734, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2821, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1669, in execute
    conn = self._connection_for_bind(bind, close_with_result=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1520, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3095, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 91, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3174, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3145, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2004, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3141, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 301, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 755, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 419, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 142, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 247, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 362, in __init__
    self.__connect(first_connect_check=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 605, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 599, in __connect
    connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 578, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 583, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres_source" to address: Temporary failure in name resolution

(Background on this error at: http://sqlalche.me/e/14/e3q8)
[2022-06-18 17:08:00,760] {processor.py:153} INFO - Started process (PID=589) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 17:08:01,193] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 17:08:01,196] {logging_mixin.py:115} INFO - [2022-06-18 17:08:01,195] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 17:08:03,287] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 17:16:20,452] {processor.py:153} INFO - Started process (PID=611) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 17:16:21,350] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 17:16:21,537] {logging_mixin.py:115} INFO - [2022-06-18 17:16:21,537] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 17:16:27,032] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 17:18:10,428] {processor.py:164} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3141, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 301, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 755, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 419, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 142, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 247, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 362, in __init__
    self.__connect(first_connect_check=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 605, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 599, in __connect
    connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 578, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 583, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres_source" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 158, in _run_file_processor
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 660, in process_file
    dagbag.sync_to_db()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 615, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 382, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 360, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 193, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 627, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 601, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 68, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 142, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2734, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2821, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1669, in execute
    conn = self._connection_for_bind(bind, close_with_result=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1520, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3095, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 91, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3174, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3145, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2004, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3141, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 301, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 755, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 419, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 142, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 247, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 362, in __init__
    self.__connect(first_connect_check=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 605, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 599, in __connect
    connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 578, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 583, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres_source" to address: Temporary failure in name resolution

(Background on this error at: http://sqlalche.me/e/14/e3q8)
[2022-06-18 19:51:57,774] {processor.py:153} INFO - Started process (PID=900) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 19:51:57,785] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 19:51:57,785] {logging_mixin.py:115} INFO - [2022-06-18 19:51:57,785] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 19:51:58,011] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 19:51:58,913] {logging_mixin.py:115} INFO - [2022-06-18 19:51:58,913] {dag.py:2379} INFO - Sync 3 DAGs
[2022-06-18 19:51:59,188] {logging_mixin.py:115} INFO - [2022-06-18 19:51:59,183] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-dimensions to 2022-06-18T17:51:59.182213+00:00, run_after=2022-06-18T19:51:59.182213+00:00
[2022-06-18 19:51:59,196] {logging_mixin.py:115} INFO - [2022-06-18 19:51:59,196] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-example to 2022-06-18T17:51:59.196455+00:00, run_after=2022-06-18T19:51:59.196455+00:00
[2022-06-18 19:51:59,197] {logging_mixin.py:115} INFO - [2022-06-18 19:51:59,197] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-objects to 2022-06-18T17:51:59.197022+00:00, run_after=2022-06-18T19:51:59.197022+00:00
[2022-06-18 19:51:59,361] {processor.py:161} INFO - Processing /opt/airflow/dags/docker_job/dbt_model.py took 1.686 seconds
[2022-06-18 20:05:04,068] {processor.py:153} INFO - Started process (PID=1106) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 20:05:04,111] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 20:05:04,283] {logging_mixin.py:115} INFO - [2022-06-18 20:05:04,283] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 20:05:04,610] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 20:05:05,891] {logging_mixin.py:115} INFO - [2022-06-18 20:05:05,891] {dag.py:2379} INFO - Sync 3 DAGs
[2022-06-18 20:05:06,007] {logging_mixin.py:115} INFO - [2022-06-18 20:05:06,007] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-dimensions to 2022-06-18T18:05:06.006368+00:00, run_after=2022-06-18T20:05:06.006368+00:00
[2022-06-18 20:05:06,008] {logging_mixin.py:115} INFO - [2022-06-18 20:05:06,008] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-example to 2022-06-18T18:05:06.007967+00:00, run_after=2022-06-18T20:05:06.007967+00:00
[2022-06-18 20:05:06,008] {logging_mixin.py:115} INFO - [2022-06-18 20:05:06,008] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-objects to 2022-06-18T18:05:06.008245+00:00, run_after=2022-06-18T20:05:06.008245+00:00
[2022-06-18 20:05:06,199] {processor.py:161} INFO - Processing /opt/airflow/dags/docker_job/dbt_model.py took 2.505 seconds
[2022-06-18 20:10:02,655] {processor.py:153} INFO - Started process (PID=1230) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 20:10:02,657] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 20:10:02,680] {logging_mixin.py:115} INFO - [2022-06-18 20:10:02,680] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 20:10:02,825] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 20:14:07,813] {processor.py:153} INFO - Started process (PID=1278) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 20:14:08,055] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 20:14:08,055] {logging_mixin.py:115} INFO - [2022-06-18 20:14:08,055] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 20:14:09,122] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 20:16:36,105] {processor.py:164} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3141, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 301, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 755, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 419, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 142, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 247, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 362, in __init__
    self.__connect(first_connect_check=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 605, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 599, in __connect
    connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 578, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 583, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres_source" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 158, in _run_file_processor
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 660, in process_file
    dagbag.sync_to_db()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 615, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 382, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 360, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 193, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 627, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 601, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 68, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 142, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2734, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2821, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1669, in execute
    conn = self._connection_for_bind(bind, close_with_result=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1520, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3095, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 91, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3174, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3145, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2004, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3141, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 301, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 755, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 419, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 142, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 247, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 362, in __init__
    self.__connect(first_connect_check=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 605, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 599, in __connect
    connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 578, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 583, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres_source" to address: Temporary failure in name resolution

(Background on this error at: http://sqlalche.me/e/14/e3q8)
[2022-06-18 20:24:26,280] {processor.py:153} INFO - Started process (PID=1395) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 20:24:26,293] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 20:24:26,294] {logging_mixin.py:115} INFO - [2022-06-18 20:24:26,294] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 20:24:27,159] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 20:24:39,571] {logging_mixin.py:115} INFO - [2022-06-18 20:24:39,438] {dag.py:2379} INFO - Sync 3 DAGs
[2022-06-18 20:35:17,219] {processor.py:153} INFO - Started process (PID=1474) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 20:35:17,250] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 20:35:17,253] {logging_mixin.py:115} INFO - [2022-06-18 20:35:17,253] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 20:35:17,641] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 20:35:57,020] {logging_mixin.py:115} INFO - [2022-06-18 20:35:52,849] {dag.py:2379} INFO - Sync 3 DAGs
[2022-06-18 20:36:01,691] {logging_mixin.py:115} INFO - [2022-06-18 20:36:01,691] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-dimensions to 2022-06-18T18:36:01.681831+00:00, run_after=2022-06-18T20:36:01.681831+00:00
[2022-06-18 20:36:01,869] {logging_mixin.py:115} INFO - [2022-06-18 20:36:01,869] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-example to 2022-06-18T18:36:01.869333+00:00, run_after=2022-06-18T20:36:01.869333+00:00
[2022-06-18 20:36:01,869] {logging_mixin.py:115} INFO - [2022-06-18 20:36:01,869] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-objects to 2022-06-18T18:36:01.869778+00:00, run_after=2022-06-18T20:36:01.869778+00:00
[2022-06-18 20:36:10,301] {processor.py:161} INFO - Processing /opt/airflow/dags/docker_job/dbt_model.py took 53.093 seconds
[2022-06-18 20:43:57,552] {processor.py:153} INFO - Started process (PID=1549) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 20:43:58,239] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 20:43:58,243] {logging_mixin.py:115} INFO - [2022-06-18 20:43:58,242] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 20:44:05,078] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 20:50:07,927] {processor.py:153} INFO - Started process (PID=1594) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 20:50:07,952] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 20:50:07,952] {logging_mixin.py:115} INFO - [2022-06-18 20:50:07,952] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 20:50:09,655] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 20:59:05,325] {processor.py:153} INFO - Started process (PID=1691) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 20:59:05,326] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 20:59:05,327] {logging_mixin.py:115} INFO - [2022-06-18 20:59:05,327] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 20:59:06,433] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 21:33:37,644] {processor.py:153} INFO - Started process (PID=1902) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 21:33:37,676] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 21:33:37,677] {logging_mixin.py:115} INFO - [2022-06-18 21:33:37,677] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 21:33:37,881] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 21:35:50,758] {logging_mixin.py:115} INFO - [2022-06-18 21:35:50,732] {dag.py:2379} INFO - Sync 3 DAGs
[2022-06-18 21:43:07,558] {processor.py:153} INFO - Started process (PID=1916) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 21:43:07,655] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 21:43:07,656] {logging_mixin.py:115} INFO - [2022-06-18 21:43:07,656] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 21:43:08,007] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 21:50:50,737] {processor.py:153} INFO - Started process (PID=1932) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 21:50:50,746] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 21:50:50,747] {logging_mixin.py:115} INFO - [2022-06-18 21:50:50,747] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 21:50:52,085] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 21:56:35,914] {processor.py:153} INFO - Started process (PID=1941) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 21:56:36,387] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 21:56:36,388] {logging_mixin.py:115} INFO - [2022-06-18 21:56:36,388] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 21:56:36,899] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 21:58:37,812] {logging_mixin.py:115} INFO - [2022-06-18 21:58:37,812] {dag.py:2379} INFO - Sync 3 DAGs
[2022-06-18 22:06:02,348] {processor.py:153} INFO - Started process (PID=1964) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 22:06:02,353] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 22:06:02,385] {logging_mixin.py:115} INFO - [2022-06-18 22:06:02,385] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 22:06:04,864] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 22:12:25,469] {processor.py:153} INFO - Started process (PID=1981) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 22:12:25,560] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 22:12:25,561] {logging_mixin.py:115} INFO - [2022-06-18 22:12:25,561] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 22:12:26,573] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 22:25:53,604] {processor.py:153} INFO - Started process (PID=2026) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 22:25:53,655] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 22:25:53,655] {logging_mixin.py:115} INFO - [2022-06-18 22:25:53,655] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 22:25:53,904] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 22:26:37,943] {logging_mixin.py:115} INFO - [2022-06-18 22:26:37,943] {dag.py:2379} INFO - Sync 3 DAGs
[2022-06-18 22:26:38,480] {logging_mixin.py:115} INFO - [2022-06-18 22:26:38,480] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-dimensions to 2022-06-18T20:26:38.479906+00:00, run_after=2022-06-18T22:26:38.479906+00:00
[2022-06-18 22:26:38,480] {logging_mixin.py:115} INFO - [2022-06-18 22:26:38,480] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-example to 2022-06-18T20:26:38.480510+00:00, run_after=2022-06-18T22:26:38.480510+00:00
[2022-06-18 22:26:38,491] {logging_mixin.py:115} INFO - [2022-06-18 22:26:38,480] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-objects to 2022-06-18T20:26:38.480750+00:00, run_after=2022-06-18T22:26:38.480750+00:00
[2022-06-18 22:26:39,137] {processor.py:161} INFO - Processing /opt/airflow/dags/docker_job/dbt_model.py took 45.717 seconds
[2022-06-18 22:33:40,981] {processor.py:153} INFO - Started process (PID=2048) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 22:33:41,118] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 22:33:41,118] {logging_mixin.py:115} INFO - [2022-06-18 22:33:41,118] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 22:33:41,245] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 22:39:49,668] {processor.py:153} INFO - Started process (PID=2076) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 22:39:49,685] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 22:39:49,687] {logging_mixin.py:115} INFO - [2022-06-18 22:39:49,687] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 22:39:50,581] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 22:40:07,524] {logging_mixin.py:115} INFO - [2022-06-18 22:40:07,460] {dag.py:2379} INFO - Sync 3 DAGs
[2022-06-18 22:41:56,136] {logging_mixin.py:115} INFO - [2022-06-18 22:41:56,136] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-dimensions to 2022-06-18T20:41:56.135383+00:00, run_after=2022-06-18T22:41:56.135383+00:00
[2022-06-18 22:41:56,139] {logging_mixin.py:115} INFO - [2022-06-18 22:41:56,139] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-example to 2022-06-18T20:41:56.139290+00:00, run_after=2022-06-18T22:41:56.139290+00:00
[2022-06-18 22:41:56,139] {logging_mixin.py:115} INFO - [2022-06-18 22:41:56,139] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-objects to 2022-06-18T20:41:56.139684+00:00, run_after=2022-06-18T22:41:56.139684+00:00
[2022-06-18 22:50:52,373] {processor.py:153} INFO - Started process (PID=2125) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 22:50:52,393] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 22:50:52,394] {logging_mixin.py:115} INFO - [2022-06-18 22:50:52,393] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 22:50:53,462] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 22:51:31,950] {logging_mixin.py:115} INFO - [2022-06-18 22:51:31,887] {dag.py:2379} INFO - Sync 3 DAGs
[2022-06-18 22:59:50,251] {processor.py:153} INFO - Started process (PID=2157) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 22:59:50,256] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 22:59:50,258] {logging_mixin.py:115} INFO - [2022-06-18 22:59:50,258] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 22:59:50,365] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 22:59:52,495] {logging_mixin.py:115} INFO - [2022-06-18 22:59:52,483] {dag.py:2379} INFO - Sync 3 DAGs
[2022-06-18 22:59:53,898] {logging_mixin.py:115} INFO - [2022-06-18 22:59:53,774] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-dimensions to 2022-06-18T20:59:53.712734+00:00, run_after=2022-06-18T22:59:53.712734+00:00
[2022-06-18 22:59:53,992] {logging_mixin.py:115} INFO - [2022-06-18 22:59:53,992] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-example to 2022-06-18T20:59:53.989522+00:00, run_after=2022-06-18T22:59:53.989522+00:00
[2022-06-18 22:59:53,997] {logging_mixin.py:115} INFO - [2022-06-18 22:59:53,996] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-objects to 2022-06-18T20:59:53.996820+00:00, run_after=2022-06-18T22:59:53.996820+00:00
[2022-06-18 22:59:58,358] {processor.py:161} INFO - Processing /opt/airflow/dags/docker_job/dbt_model.py took 8.116 seconds
[2022-06-18 23:03:31,385] {processor.py:153} INFO - Started process (PID=2174) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 23:03:31,391] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 23:03:31,399] {logging_mixin.py:115} INFO - [2022-06-18 23:03:31,398] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 23:03:31,661] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 23:04:09,435] {logging_mixin.py:115} INFO - [2022-06-18 23:04:09,435] {dag.py:2379} INFO - Sync 3 DAGs
[2022-06-18 23:04:09,549] {logging_mixin.py:115} INFO - [2022-06-18 23:04:09,549] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-dimensions to 2022-06-18T21:04:09.539278+00:00, run_after=2022-06-18T23:04:09.539278+00:00
[2022-06-18 23:04:09,551] {logging_mixin.py:115} INFO - [2022-06-18 23:04:09,551] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-example to 2022-06-18T21:04:09.549972+00:00, run_after=2022-06-18T23:04:09.549972+00:00
[2022-06-18 23:04:09,551] {logging_mixin.py:115} INFO - [2022-06-18 23:04:09,551] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-objects to 2022-06-18T21:04:09.551362+00:00, run_after=2022-06-18T23:04:09.551362+00:00
[2022-06-18 23:04:10,362] {processor.py:161} INFO - Processing /opt/airflow/dags/docker_job/dbt_model.py took 39.181 seconds
[2022-06-18 23:11:11,250] {processor.py:153} INFO - Started process (PID=2204) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 23:11:11,605] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 23:11:11,611] {logging_mixin.py:115} INFO - [2022-06-18 23:11:11,611] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 23:11:12,991] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 23:11:20,250] {logging_mixin.py:115} INFO - [2022-06-18 23:11:20,250] {dag.py:2379} INFO - Sync 3 DAGs
[2022-06-18 23:11:20,760] {logging_mixin.py:115} INFO - [2022-06-18 23:11:20,760] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-dimensions to 2022-06-18T21:11:20.758476+00:00, run_after=2022-06-18T23:11:20.758476+00:00
[2022-06-18 23:11:20,762] {logging_mixin.py:115} INFO - [2022-06-18 23:11:20,762] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-example to 2022-06-18T21:11:20.761967+00:00, run_after=2022-06-18T23:11:20.761967+00:00
[2022-06-18 23:11:20,762] {logging_mixin.py:115} INFO - [2022-06-18 23:11:20,762] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-objects to 2022-06-18T21:11:20.762287+00:00, run_after=2022-06-18T23:11:20.762287+00:00
[2022-06-18 23:11:21,329] {processor.py:161} INFO - Processing /opt/airflow/dags/docker_job/dbt_model.py took 10.646 seconds
[2022-06-18 23:20:42,809] {processor.py:153} INFO - Started process (PID=2230) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 23:20:42,810] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 23:20:42,868] {logging_mixin.py:115} INFO - [2022-06-18 23:20:42,810] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 23:20:43,331] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 23:22:59,335] {logging_mixin.py:115} INFO - [2022-06-18 23:22:59,335] {dag.py:2379} INFO - Sync 3 DAGs
[2022-06-18 23:29:14,104] {processor.py:153} INFO - Started process (PID=2261) to work on /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 23:29:14,146] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_model.py for tasks to queue
[2022-06-18 23:29:14,310] {logging_mixin.py:115} INFO - [2022-06-18 23:29:14,310] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_model.py
[2022-06-18 23:29:14,836] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-example', 'T-dbt-job-dimensions', 'T-dbt-job-objects']) retrieved from /opt/airflow/dags/docker_job/dbt_model.py
