[2022-06-18 00:03:22,307] {processor.py:153} INFO - Started process (PID=9502) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 00:03:22,307] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 00:03:22,308] {logging_mixin.py:115} INFO - [2022-06-18 00:03:22,308] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 00:03:24,062] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 00:03:35,094] {logging_mixin.py:115} INFO - [2022-06-18 00:03:35,094] {dag.py:2379} INFO - Sync 1 DAGs
[2022-06-18 00:03:54,200] {logging_mixin.py:115} INFO - [2022-06-18 00:03:54,045] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-cdc_load to 2022-06-17T22:03:49.760826+00:00, run_after=2022-06-18T00:03:49.760826+00:00
[2022-06-18 00:04:12,353] {processor.py:161} INFO - Processing /opt/airflow/dags/docker_job/dbt_test.py took 50.312 seconds
[2022-06-18 00:09:13,247] {processor.py:153} INFO - Started process (PID=9582) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 00:09:13,321] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 00:09:13,328] {logging_mixin.py:115} INFO - [2022-06-18 00:09:13,325] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 00:09:22,869] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 00:09:50,302] {logging_mixin.py:115} INFO - [2022-06-18 00:09:49,726] {dag.py:2379} INFO - Sync 1 DAGs
[2022-06-18 00:15:28,393] {processor.py:153} INFO - Started process (PID=9637) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 00:15:28,418] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 00:15:28,418] {logging_mixin.py:115} INFO - [2022-06-18 00:15:28,418] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 00:15:29,475] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 00:16:00,236] {logging_mixin.py:115} INFO - [2022-06-18 00:16:00,236] {dag.py:2379} INFO - Sync 1 DAGs
[2022-06-18 00:16:02,738] {logging_mixin.py:115} INFO - [2022-06-18 00:16:02,715] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-cdc_load to 2022-06-17T22:16:02.651249+00:00, run_after=2022-06-18T00:16:02.651249+00:00
[2022-06-18 00:16:08,166] {processor.py:161} INFO - Processing /opt/airflow/dags/docker_job/dbt_test.py took 40.020 seconds
[2022-06-18 00:21:22,838] {processor.py:153} INFO - Started process (PID=9766) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 00:21:22,881] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 00:21:22,883] {logging_mixin.py:115} INFO - [2022-06-18 00:21:22,883] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 00:21:28,909] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 00:22:11,087] {logging_mixin.py:115} INFO - [2022-06-18 00:22:11,087] {dag.py:2379} INFO - Sync 1 DAGs
[2022-06-18 00:22:11,652] {logging_mixin.py:115} INFO - [2022-06-18 00:22:11,651] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-cdc_load to 2022-06-17T22:22:11.450257+00:00, run_after=2022-06-18T00:22:11.450257+00:00
[2022-06-18 00:22:12,046] {processor.py:161} INFO - Processing /opt/airflow/dags/docker_job/dbt_test.py took 49.543 seconds
[2022-06-18 00:26:18,693] {processor.py:153} INFO - Started process (PID=9907) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 00:26:18,754] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 00:26:18,757] {logging_mixin.py:115} INFO - [2022-06-18 00:26:18,757] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 00:26:20,217] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 00:26:25,781] {logging_mixin.py:115} INFO - [2022-06-18 00:26:25,781] {dag.py:2379} INFO - Sync 1 DAGs
[2022-06-18 00:26:32,295] {logging_mixin.py:115} INFO - [2022-06-18 00:26:32,286] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-cdc_load to 2022-06-17T22:26:32.231616+00:00, run_after=2022-06-18T00:26:32.231616+00:00
[2022-06-18 00:26:44,281] {processor.py:161} INFO - Processing /opt/airflow/dags/docker_job/dbt_test.py took 25.623 seconds
[2022-06-18 00:30:21,642] {processor.py:153} INFO - Started process (PID=9966) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 00:30:21,880] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 00:30:21,880] {logging_mixin.py:115} INFO - [2022-06-18 00:30:21,880] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 00:30:28,289] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 00:35:05,384] {processor.py:153} INFO - Started process (PID=10085) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 00:35:05,396] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 00:35:05,397] {logging_mixin.py:115} INFO - [2022-06-18 00:35:05,397] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 00:35:06,785] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 00:35:08,479] {logging_mixin.py:115} INFO - [2022-06-18 00:35:08,479] {dag.py:2379} INFO - Sync 1 DAGs
[2022-06-18 00:35:08,823] {logging_mixin.py:115} INFO - [2022-06-18 00:35:08,822] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-cdc_load to 2022-06-17T22:35:08.800342+00:00, run_after=2022-06-18T00:35:08.800342+00:00
[2022-06-18 00:35:09,593] {processor.py:161} INFO - Processing /opt/airflow/dags/docker_job/dbt_test.py took 4.431 seconds
[2022-06-18 00:37:38,226] {processor.py:153} INFO - Started process (PID=10230) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 00:37:38,262] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 00:37:38,268] {logging_mixin.py:115} INFO - [2022-06-18 00:37:38,267] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 00:37:39,660] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 00:41:13,834] {processor.py:153} INFO - Started process (PID=10338) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 00:41:13,901] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 00:41:14,651] {logging_mixin.py:115} INFO - [2022-06-18 00:41:14,395] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 00:41:30,736] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 00:47:18,073] {processor.py:153} INFO - Started process (PID=10405) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 00:47:18,361] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 00:47:18,361] {logging_mixin.py:115} INFO - [2022-06-18 00:47:18,361] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 00:47:21,171] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 00:59:47,980] {processor.py:153} INFO - Started process (PID=10744) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 00:59:47,984] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 00:59:47,985] {logging_mixin.py:115} INFO - [2022-06-18 00:59:47,985] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 00:59:58,727] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 01:06:32,523] {processor.py:153} INFO - Started process (PID=194) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 01:06:32,524] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 01:06:32,524] {logging_mixin.py:115} INFO - [2022-06-18 01:06:32,524] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 01:06:32,538] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 01:06:32,560] {logging_mixin.py:115} INFO - [2022-06-18 01:06:32,559] {dag.py:2379} INFO - Sync 1 DAGs
[2022-06-18 01:06:32,579] {logging_mixin.py:115} INFO - [2022-06-18 01:06:32,579] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-cdc_load to 2022-06-17T23:06:32.579139+00:00, run_after=2022-06-18T01:06:32.579139+00:00
[2022-06-18 01:06:32,587] {processor.py:161} INFO - Processing /opt/airflow/dags/docker_job/dbt_test.py took 0.069 seconds
[2022-06-18 01:07:03,397] {processor.py:153} INFO - Started process (PID=441) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 01:07:03,398] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 01:07:03,398] {logging_mixin.py:115} INFO - [2022-06-18 01:07:03,398] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 01:07:03,412] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 01:07:03,436] {logging_mixin.py:115} INFO - [2022-06-18 01:07:03,436] {dag.py:2379} INFO - Sync 1 DAGs
[2022-06-18 01:07:03,455] {logging_mixin.py:115} INFO - [2022-06-18 01:07:03,455] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-cdc_load to 2022-06-17T23:07:03.455000+00:00, run_after=2022-06-18T01:07:03.455000+00:00
[2022-06-18 01:07:03,464] {processor.py:161} INFO - Processing /opt/airflow/dags/docker_job/dbt_test.py took 0.070 seconds
[2022-06-18 01:07:34,339] {processor.py:153} INFO - Started process (PID=682) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 01:07:34,340] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 01:07:34,341] {logging_mixin.py:115} INFO - [2022-06-18 01:07:34,340] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 01:07:34,353] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 01:07:34,375] {logging_mixin.py:115} INFO - [2022-06-18 01:07:34,375] {dag.py:2379} INFO - Sync 1 DAGs
[2022-06-18 01:07:34,393] {logging_mixin.py:115} INFO - [2022-06-18 01:07:34,393] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-cdc_load to 2022-06-17T23:07:34.393360+00:00, run_after=2022-06-18T01:07:34.393360+00:00
[2022-06-18 01:07:34,403] {processor.py:161} INFO - Processing /opt/airflow/dags/docker_job/dbt_test.py took 0.067 seconds
[2022-06-18 01:08:05,271] {processor.py:153} INFO - Started process (PID=922) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 01:08:05,272] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 01:08:05,272] {logging_mixin.py:115} INFO - [2022-06-18 01:08:05,272] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 01:08:05,286] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 01:08:05,309] {logging_mixin.py:115} INFO - [2022-06-18 01:08:05,309] {dag.py:2379} INFO - Sync 1 DAGs
[2022-06-18 01:08:05,328] {logging_mixin.py:115} INFO - [2022-06-18 01:08:05,327] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-cdc_load to 2022-06-17T23:08:05.327753+00:00, run_after=2022-06-18T01:08:05.327753+00:00
[2022-06-18 01:08:05,441] {processor.py:161} INFO - Processing /opt/airflow/dags/docker_job/dbt_test.py took 0.173 seconds
[2022-06-18 01:08:35,677] {processor.py:153} INFO - Started process (PID=1162) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 01:08:35,678] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 01:08:35,678] {logging_mixin.py:115} INFO - [2022-06-18 01:08:35,678] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 01:08:35,691] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 01:08:35,711] {logging_mixin.py:115} INFO - [2022-06-18 01:08:35,711] {dag.py:2379} INFO - Sync 1 DAGs
[2022-06-18 01:08:35,825] {logging_mixin.py:115} INFO - [2022-06-18 01:08:35,825] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-cdc_load to 2022-06-17T23:08:35.825263+00:00, run_after=2022-06-18T01:08:35.825263+00:00
[2022-06-18 01:08:35,832] {processor.py:161} INFO - Processing /opt/airflow/dags/docker_job/dbt_test.py took 0.158 seconds
[2022-06-18 01:09:06,742] {processor.py:153} INFO - Started process (PID=1424) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 01:09:06,744] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 01:09:06,744] {logging_mixin.py:115} INFO - [2022-06-18 01:09:06,744] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 01:09:06,761] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 01:09:06,784] {logging_mixin.py:115} INFO - [2022-06-18 01:09:06,784] {dag.py:2379} INFO - Sync 1 DAGs
[2022-06-18 01:09:06,904] {logging_mixin.py:115} INFO - [2022-06-18 01:09:06,904] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-cdc_load to 2022-06-17T23:09:06.904701+00:00, run_after=2022-06-18T01:09:06.904701+00:00
[2022-06-18 01:09:06,913] {processor.py:161} INFO - Processing /opt/airflow/dags/docker_job/dbt_test.py took 0.175 seconds
[2022-06-18 01:09:37,390] {processor.py:153} INFO - Started process (PID=1674) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 01:09:37,391] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 01:09:37,391] {logging_mixin.py:115} INFO - [2022-06-18 01:09:37,391] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 01:09:37,414] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 01:09:37,559] {logging_mixin.py:115} INFO - [2022-06-18 01:09:37,559] {dag.py:2379} INFO - Sync 1 DAGs
[2022-06-18 01:09:37,573] {logging_mixin.py:115} INFO - [2022-06-18 01:09:37,573] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-cdc_load to 2022-06-17T23:09:37.573694+00:00, run_after=2022-06-18T01:09:37.573694+00:00
[2022-06-18 01:09:37,581] {processor.py:161} INFO - Processing /opt/airflow/dags/docker_job/dbt_test.py took 0.197 seconds
[2022-06-18 01:10:07,705] {processor.py:153} INFO - Started process (PID=1918) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 01:10:07,706] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 01:10:07,706] {logging_mixin.py:115} INFO - [2022-06-18 01:10:07,706] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 01:10:07,721] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 01:10:07,838] {logging_mixin.py:115} INFO - [2022-06-18 01:10:07,838] {dag.py:2379} INFO - Sync 1 DAGs
[2022-06-18 01:10:07,853] {logging_mixin.py:115} INFO - [2022-06-18 01:10:07,853] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-cdc_load to 2022-06-17T23:10:07.853205+00:00, run_after=2022-06-18T01:10:07.853205+00:00
[2022-06-18 01:10:07,861] {processor.py:161} INFO - Processing /opt/airflow/dags/docker_job/dbt_test.py took 0.158 seconds
[2022-06-18 01:10:38,879] {processor.py:153} INFO - Started process (PID=2158) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 01:10:38,880] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 01:10:38,880] {logging_mixin.py:115} INFO - [2022-06-18 01:10:38,880] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 01:10:38,998] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 01:10:39,013] {logging_mixin.py:115} INFO - [2022-06-18 01:10:39,013] {dag.py:2379} INFO - Sync 1 DAGs
[2022-06-18 01:10:39,027] {logging_mixin.py:115} INFO - [2022-06-18 01:10:39,027] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-cdc_load to 2022-06-17T23:10:39.027610+00:00, run_after=2022-06-18T01:10:39.027610+00:00
[2022-06-18 01:10:39,035] {processor.py:161} INFO - Processing /opt/airflow/dags/docker_job/dbt_test.py took 0.158 seconds
[2022-06-18 08:47:50,830] {processor.py:153} INFO - Started process (PID=2414) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 08:47:50,833] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 08:47:50,833] {logging_mixin.py:115} INFO - [2022-06-18 08:47:50,833] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 08:47:51,130] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 08:47:51,208] {logging_mixin.py:115} INFO - [2022-06-18 08:47:51,208] {dag.py:2379} INFO - Sync 1 DAGs
[2022-06-18 08:47:51,272] {logging_mixin.py:115} INFO - [2022-06-18 08:47:51,272] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-cdc_load to 2022-06-18T06:47:51.272212+00:00, run_after=2022-06-18T08:47:51.272212+00:00
[2022-06-18 08:47:51,310] {processor.py:161} INFO - Processing /opt/airflow/dags/docker_job/dbt_test.py took 0.498 seconds
[2022-06-18 08:49:54,186] {processor.py:153} INFO - Started process (PID=2681) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 08:49:54,224] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 08:49:54,224] {logging_mixin.py:115} INFO - [2022-06-18 08:49:54,224] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 08:49:55,105] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 08:49:56,038] {logging_mixin.py:115} INFO - [2022-06-18 08:49:56,038] {dag.py:2379} INFO - Sync 1 DAGs
[2022-06-18 08:49:56,617] {logging_mixin.py:115} INFO - [2022-06-18 08:49:56,617] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-cdc_load to 2022-06-18T06:49:56.617134+00:00, run_after=2022-06-18T08:49:56.617134+00:00
[2022-06-18 08:51:56,647] {processor.py:161} INFO - Processing /opt/airflow/dags/docker_job/dbt_test.py took 122.614 seconds
[2022-06-18 08:55:03,018] {processor.py:153} INFO - Started process (PID=2726) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 08:55:03,022] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 08:55:03,022] {logging_mixin.py:115} INFO - [2022-06-18 08:55:03,022] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 08:55:03,567] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 08:55:03,831] {logging_mixin.py:115} INFO - [2022-06-18 08:55:03,831] {dag.py:2379} INFO - Sync 1 DAGs
[2022-06-18 08:55:04,065] {logging_mixin.py:115} INFO - [2022-06-18 08:55:04,064] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-cdc_load to 2022-06-18T06:55:04.064680+00:00, run_after=2022-06-18T08:55:04.064680+00:00
[2022-06-18 08:55:04,127] {processor.py:161} INFO - Processing /opt/airflow/dags/docker_job/dbt_test.py took 1.390 seconds
[2022-06-18 08:58:42,603] {processor.py:153} INFO - Started process (PID=2779) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 08:58:42,609] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 08:58:42,611] {logging_mixin.py:115} INFO - [2022-06-18 08:58:42,610] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 08:58:45,077] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 08:59:10,824] {logging_mixin.py:115} INFO - [2022-06-18 08:59:10,823] {dag.py:2379} INFO - Sync 1 DAGs
[2022-06-18 08:59:11,525] {logging_mixin.py:115} INFO - [2022-06-18 08:59:11,525] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-cdc_load to 2022-06-18T06:59:11.524700+00:00, run_after=2022-06-18T08:59:11.524700+00:00
[2022-06-18 08:59:11,890] {processor.py:161} INFO - Processing /opt/airflow/dags/docker_job/dbt_test.py took 29.465 seconds
[2022-06-18 09:02:51,080] {processor.py:153} INFO - Started process (PID=2976) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 09:02:51,550] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 09:02:51,552] {logging_mixin.py:115} INFO - [2022-06-18 09:02:51,551] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 09:03:38,998] {logging_mixin.py:115} INFO - [2022-06-18 09:03:29,846] {timeout.py:67} ERROR - Process timed out, PID: 2976
[2022-06-18 09:03:53,075] {logging_mixin.py:115} INFO - [2022-06-18 09:03:43,234] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/docker_job/dbt_test.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/docker_job/dbt_test.py", line 8, in <module>
    from airflow.operators.bash_operator import BashOperator
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/bash_operator.py", line 22, in <module>
    from airflow.operators.bash import BashOperator  # noqa
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/bash.py", line 23, in <module>
    from airflow.hooks.subprocess import SubprocessHook
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/hooks/subprocess.py", line 27, in <module>
    SubprocessResult = namedtuple('SubprocessResult', ['exit_code', 'output'])
  File "/usr/local/lib/python3.7/collections/__init__.py", line 397, in namedtuple
    exec(s, namespace)
  File "<string>", line 1, in <module>
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/docker_job/dbt_test.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.2/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.2/best-practices.html#reducing-dag-complexity, PID: 2976
[2022-06-18 09:03:53,080] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 09:06:34,590] {processor.py:153} INFO - Started process (PID=3058) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 09:06:34,608] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 09:06:34,636] {logging_mixin.py:115} INFO - [2022-06-18 09:06:34,636] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 09:06:34,774] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 09:06:34,804] {logging_mixin.py:115} INFO - [2022-06-18 09:06:34,803] {dag.py:2379} INFO - Sync 1 DAGs
[2022-06-18 09:06:34,889] {logging_mixin.py:115} INFO - [2022-06-18 09:06:34,859] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-cdc_load to 2022-06-18T07:06:34.859693+00:00, run_after=2022-06-18T09:06:34.859693+00:00
[2022-06-18 09:06:35,137] {processor.py:161} INFO - Processing /opt/airflow/dags/docker_job/dbt_test.py took 0.574 seconds
[2022-06-18 09:10:06,392] {processor.py:153} INFO - Started process (PID=3153) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 09:10:06,398] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 09:10:06,398] {logging_mixin.py:115} INFO - [2022-06-18 09:10:06,398] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 09:10:06,651] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 09:10:06,859] {logging_mixin.py:115} INFO - [2022-06-18 09:10:06,858] {dag.py:2379} INFO - Sync 1 DAGs
[2022-06-18 09:10:06,886] {logging_mixin.py:115} INFO - [2022-06-18 09:10:06,886] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-cdc_load to 2022-06-18T07:10:06.886177+00:00, run_after=2022-06-18T09:10:06.886177+00:00
[2022-06-18 09:10:06,906] {processor.py:161} INFO - Processing /opt/airflow/dags/docker_job/dbt_test.py took 0.534 seconds
[2022-06-18 09:12:57,951] {processor.py:153} INFO - Started process (PID=3271) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 09:12:57,966] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 09:12:57,967] {logging_mixin.py:115} INFO - [2022-06-18 09:12:57,967] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 09:12:59,626] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 09:13:00,885] {logging_mixin.py:115} INFO - [2022-06-18 09:13:00,885] {dag.py:2379} INFO - Sync 1 DAGs
[2022-06-18 09:13:03,117] {logging_mixin.py:115} INFO - [2022-06-18 09:13:03,117] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-cdc_load to 2022-06-18T07:13:03.113725+00:00, run_after=2022-06-18T09:13:03.113725+00:00
[2022-06-18 09:15:10,686] {processor.py:161} INFO - Processing /opt/airflow/dags/docker_job/dbt_test.py took 133.002 seconds
[2022-06-18 09:17:35,795] {processor.py:153} INFO - Started process (PID=3331) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 09:17:35,798] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 09:17:35,799] {logging_mixin.py:115} INFO - [2022-06-18 09:17:35,799] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 09:17:36,220] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 09:17:36,992] {logging_mixin.py:115} INFO - [2022-06-18 09:17:36,992] {dag.py:2379} INFO - Sync 1 DAGs
[2022-06-18 09:17:37,133] {logging_mixin.py:115} INFO - [2022-06-18 09:17:37,133] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-cdc_load to 2022-06-18T07:17:37.132729+00:00, run_after=2022-06-18T09:17:37.132729+00:00
[2022-06-18 09:17:37,337] {processor.py:161} INFO - Processing /opt/airflow/dags/docker_job/dbt_test.py took 1.850 seconds
[2022-06-18 09:20:44,153] {processor.py:153} INFO - Started process (PID=3582) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 09:20:44,189] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 09:20:44,189] {logging_mixin.py:115} INFO - [2022-06-18 09:20:44,189] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 09:20:45,184] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 09:20:46,893] {logging_mixin.py:115} INFO - [2022-06-18 09:20:46,893] {dag.py:2379} INFO - Sync 1 DAGs
[2022-06-18 09:20:47,155] {logging_mixin.py:115} INFO - [2022-06-18 09:20:47,155] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-cdc_load to 2022-06-18T07:20:47.154705+00:00, run_after=2022-06-18T09:20:47.154705+00:00
[2022-06-18 09:20:47,576] {processor.py:161} INFO - Processing /opt/airflow/dags/docker_job/dbt_test.py took 3.575 seconds
[2022-06-18 09:21:34,529] {processor.py:153} INFO - Started process (PID=3616) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 09:21:34,530] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 09:21:34,530] {logging_mixin.py:115} INFO - [2022-06-18 09:21:34,530] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 09:21:34,994] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 09:21:38,256] {logging_mixin.py:115} INFO - [2022-06-18 09:21:38,253] {dag.py:2379} INFO - Sync 1 DAGs
[2022-06-18 09:21:38,371] {logging_mixin.py:115} INFO - [2022-06-18 09:21:38,371] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-cdc_load to 2022-06-18T07:21:38.366942+00:00, run_after=2022-06-18T09:21:38.366942+00:00
[2022-06-18 09:21:38,456] {processor.py:161} INFO - Processing /opt/airflow/dags/docker_job/dbt_test.py took 3.931 seconds
[2022-06-18 09:23:17,198] {processor.py:153} INFO - Started process (PID=3645) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 09:23:17,863] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 09:23:18,452] {logging_mixin.py:115} INFO - [2022-06-18 09:23:18,452] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 09:23:40,207] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 09:23:42,104] {logging_mixin.py:115} INFO - [2022-06-18 09:23:42,090] {dag.py:2379} INFO - Sync 1 DAGs
[2022-06-18 09:23:42,291] {logging_mixin.py:115} INFO - [2022-06-18 09:23:42,290] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-cdc_load to 2022-06-18T07:23:42.274250+00:00, run_after=2022-06-18T09:23:42.274250+00:00
[2022-06-18 09:23:42,480] {processor.py:161} INFO - Processing /opt/airflow/dags/docker_job/dbt_test.py took 26.247 seconds
[2022-06-18 09:27:01,902] {processor.py:153} INFO - Started process (PID=3686) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 09:27:02,221] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 09:27:02,350] {logging_mixin.py:115} INFO - [2022-06-18 09:27:02,349] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 09:28:03,095] {logging_mixin.py:115} INFO - [2022-06-18 09:28:00,765] {timeout.py:67} ERROR - Process timed out, PID: 3686
[2022-06-18 09:28:07,060] {logging_mixin.py:115} INFO - [2022-06-18 09:28:03,127] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/docker_job/dbt_test.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/docker_job/dbt_test.py", line 6, in <module>
    from airflow import DAG
  File "<frozen importlib._bootstrap>", line 1032, in _handle_fromlist
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/__init__.py", line 71, in __getattr__
    import operator
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/docker_job/dbt_test.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.2/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.2/best-practices.html#reducing-dag-complexity, PID: 3686
[2022-06-18 09:28:07,105] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 09:28:08,213] {processor.py:161} INFO - Processing /opt/airflow/dags/docker_job/dbt_test.py took 67.378 seconds
[2022-06-18 09:32:14,261] {processor.py:153} INFO - Started process (PID=3773) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 09:32:14,284] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 09:32:14,285] {logging_mixin.py:115} INFO - [2022-06-18 09:32:14,284] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 09:32:15,695] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 09:32:16,054] {logging_mixin.py:115} INFO - [2022-06-18 09:32:16,054] {dag.py:2379} INFO - Sync 1 DAGs
[2022-06-18 09:32:16,314] {logging_mixin.py:115} INFO - [2022-06-18 09:32:16,314] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-cdc_load to 2022-06-18T07:32:16.313809+00:00, run_after=2022-06-18T09:32:16.313809+00:00
[2022-06-18 09:32:16,406] {processor.py:161} INFO - Processing /opt/airflow/dags/docker_job/dbt_test.py took 2.457 seconds
[2022-06-18 09:35:46,047] {processor.py:153} INFO - Started process (PID=3919) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 09:35:46,051] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 09:35:46,052] {logging_mixin.py:115} INFO - [2022-06-18 09:35:46,052] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 09:35:46,680] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 09:35:47,227] {logging_mixin.py:115} INFO - [2022-06-18 09:35:47,227] {dag.py:2379} INFO - Sync 1 DAGs
[2022-06-18 09:35:47,340] {logging_mixin.py:115} INFO - [2022-06-18 09:35:47,339] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-cdc_load to 2022-06-18T07:35:47.339580+00:00, run_after=2022-06-18T09:35:47.339580+00:00
[2022-06-18 09:35:47,457] {processor.py:161} INFO - Processing /opt/airflow/dags/docker_job/dbt_test.py took 1.415 seconds
[2022-06-18 09:40:51,237] {processor.py:153} INFO - Started process (PID=3987) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 09:40:51,242] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 09:40:51,242] {logging_mixin.py:115} INFO - [2022-06-18 09:40:51,242] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 09:40:52,557] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 09:46:08,195] {processor.py:153} INFO - Started process (PID=4101) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 09:46:08,211] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 09:46:08,211] {logging_mixin.py:115} INFO - [2022-06-18 09:46:08,211] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 09:46:08,426] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 09:46:09,799] {logging_mixin.py:115} INFO - [2022-06-18 09:46:09,799] {dag.py:2379} INFO - Sync 1 DAGs
[2022-06-18 09:46:10,042] {logging_mixin.py:115} INFO - [2022-06-18 09:46:10,042] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-cdc_load to 2022-06-18T07:46:10.040835+00:00, run_after=2022-06-18T09:46:10.040835+00:00
[2022-06-18 09:46:10,204] {processor.py:161} INFO - Processing /opt/airflow/dags/docker_job/dbt_test.py took 2.012 seconds
[2022-06-18 09:52:16,157] {processor.py:153} INFO - Started process (PID=4270) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 09:52:16,327] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 09:52:16,328] {logging_mixin.py:115} INFO - [2022-06-18 09:52:16,328] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 09:52:17,492] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 09:56:31,361] {processor.py:153} INFO - Started process (PID=4299) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 09:56:31,486] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 09:56:31,672] {logging_mixin.py:115} INFO - [2022-06-18 09:56:31,672] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 09:56:41,799] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 10:00:16,121] {processor.py:153} INFO - Started process (PID=4356) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 10:00:16,167] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 10:00:16,167] {logging_mixin.py:115} INFO - [2022-06-18 10:00:16,167] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 10:00:22,665] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 10:06:08,956] {processor.py:153} INFO - Started process (PID=4489) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 10:06:08,970] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 10:06:08,971] {logging_mixin.py:115} INFO - [2022-06-18 10:06:08,971] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 10:06:10,227] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 10:08:16,521] {processor.py:153} INFO - Started process (PID=4544) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 10:08:16,524] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 10:08:16,524] {logging_mixin.py:115} INFO - [2022-06-18 10:08:16,524] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 10:08:18,370] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 10:10:41,905] {logging_mixin.py:115} INFO - [2022-06-18 10:10:41,905] {dag.py:2379} INFO - Sync 1 DAGs
[2022-06-18 10:13:09,074] {processor.py:153} INFO - Started process (PID=4574) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 10:13:09,133] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 10:13:09,134] {logging_mixin.py:115} INFO - [2022-06-18 10:13:09,134] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 10:13:10,544] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 10:19:50,523] {processor.py:153} INFO - Started process (PID=4723) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 10:19:50,568] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 10:19:50,569] {logging_mixin.py:115} INFO - [2022-06-18 10:19:50,569] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 10:19:51,068] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 10:19:51,912] {logging_mixin.py:115} INFO - [2022-06-18 10:19:51,911] {dag.py:2379} INFO - Sync 1 DAGs
[2022-06-18 10:19:52,122] {logging_mixin.py:115} INFO - [2022-06-18 10:19:52,121] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-cdc_load to 2022-06-18T08:19:52.119180+00:00, run_after=2022-06-18T10:19:52.119180+00:00
[2022-06-18 10:19:53,656] {processor.py:161} INFO - Processing /opt/airflow/dags/docker_job/dbt_test.py took 3.134 seconds
[2022-06-18 10:31:32,763] {processor.py:153} INFO - Started process (PID=4818) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 10:31:32,770] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 10:31:32,849] {logging_mixin.py:115} INFO - [2022-06-18 10:31:32,849] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 10:32:26,827] {logging_mixin.py:115} INFO - [2022-06-18 10:32:16,688] {timeout.py:67} ERROR - Process timed out, PID: 4818
[2022-06-18 10:32:32,079] {logging_mixin.py:115} INFO - [2022-06-18 10:32:26,838] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/docker_job/dbt_test.py
Traceback (most recent call last):
  File "<frozen importlib._bootstrap_external>", line 87, in _path_is_mode_type
  File "<frozen importlib._bootstrap_external>", line 81, in _path_stat
FileNotFoundError: [Errno 2] No such file or directory: '/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/postgres/hooks/__init__.abi3.so'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/docker_job/dbt_test.py", line 7, in <module>
    from airflow.hooks.postgres_hook import PostgresHook
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/hooks/postgres_hook.py", line 22, in <module>
    from airflow.providers.postgres.hooks.postgres import PostgresHook  # noqa
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 963, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 906, in _find_spec
  File "<frozen importlib._bootstrap_external>", line 1280, in find_spec
  File "<frozen importlib._bootstrap_external>", line 1252, in _get_spec
  File "<frozen importlib._bootstrap_external>", line 1383, in find_spec
  File "<frozen importlib._bootstrap_external>", line 95, in _path_isfile
  File "<frozen importlib._bootstrap_external>", line 87, in _path_is_mode_type
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/docker_job/dbt_test.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.2/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.2/best-practices.html#reducing-dag-complexity, PID: 4818
[2022-06-18 10:32:32,846] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 10:33:31,468] {processor.py:164} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3141, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 301, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 755, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 419, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 142, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 247, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 362, in __init__
    self.__connect(first_connect_check=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 605, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 599, in __connect
    connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 578, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 583, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres_source" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 158, in _run_file_processor
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 654, in process_file
    self.update_import_errors(session, dagbag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 541, in update_import_errors
    existing_import_error_files = [x.filename for x in session.query(errors.ImportError.filename).all()]
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2683, in all
    return self._iter().all()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2821, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1669, in execute
    conn = self._connection_for_bind(bind, close_with_result=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1520, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3095, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 91, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3174, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3145, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2004, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3141, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 301, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 755, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 419, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 142, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 247, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 362, in __init__
    self.__connect(first_connect_check=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 605, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 599, in __connect
    connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 578, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 583, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres_source" to address: Temporary failure in name resolution

(Background on this error at: http://sqlalche.me/e/14/e3q8)
[2022-06-18 10:34:50,379] {processor.py:153} INFO - Started process (PID=4879) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 10:34:50,777] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 10:34:50,863] {logging_mixin.py:115} INFO - [2022-06-18 10:34:50,863] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 10:34:54,962] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 12:28:52,592] {processor.py:153} INFO - Started process (PID=5028) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 12:28:52,599] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 12:28:52,600] {logging_mixin.py:115} INFO - [2022-06-18 12:28:52,599] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 12:28:52,644] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 12:28:52,679] {logging_mixin.py:115} INFO - [2022-06-18 12:28:52,678] {dag.py:2379} INFO - Sync 1 DAGs
[2022-06-18 12:28:52,772] {logging_mixin.py:115} INFO - [2022-06-18 12:28:52,772] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-cdc_load to 2022-06-18T10:28:52.771794+00:00, run_after=2022-06-18T12:28:52.771794+00:00
[2022-06-18 12:28:52,878] {processor.py:161} INFO - Processing /opt/airflow/dags/docker_job/dbt_test.py took 0.292 seconds
[2022-06-18 12:36:05,559] {processor.py:153} INFO - Started process (PID=5239) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 12:36:05,571] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 12:36:05,712] {logging_mixin.py:115} INFO - [2022-06-18 12:36:05,711] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 12:36:07,341] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 12:45:01,704] {processor.py:153} INFO - Started process (PID=5371) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 12:45:01,740] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 12:45:01,746] {logging_mixin.py:115} INFO - [2022-06-18 12:45:01,746] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 12:45:04,720] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 12:46:00,764] {logging_mixin.py:115} INFO - [2022-06-18 12:46:00,764] {dag.py:2379} INFO - Sync 1 DAGs
[2022-06-18 12:52:20,949] {processor.py:153} INFO - Started process (PID=218) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 12:52:20,951] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 12:52:20,952] {logging_mixin.py:115} INFO - [2022-06-18 12:52:20,952] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 12:52:20,975] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 12:52:21,043] {logging_mixin.py:115} INFO - [2022-06-18 12:52:21,042] {dag.py:2379} INFO - Sync 1 DAGs
[2022-06-18 12:52:21,096] {logging_mixin.py:115} INFO - [2022-06-18 12:52:21,096] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-cdc_load to 2022-06-18T10:52:21.096266+00:00, run_after=2022-06-18T12:52:21.096266+00:00
[2022-06-18 12:52:21,152] {processor.py:161} INFO - Processing /opt/airflow/dags/docker_job/dbt_test.py took 0.211 seconds
[2022-06-18 12:53:25,722] {processor.py:153} INFO - Started process (PID=310) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 12:53:25,730] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 12:53:25,730] {logging_mixin.py:115} INFO - [2022-06-18 12:53:25,730] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 12:53:26,649] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 12:53:29,984] {logging_mixin.py:115} INFO - [2022-06-18 12:53:29,984] {dag.py:2379} INFO - Sync 1 DAGs
[2022-06-18 12:53:30,442] {logging_mixin.py:115} INFO - [2022-06-18 12:53:30,442] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-cdc_load to 2022-06-18T10:53:30.438054+00:00, run_after=2022-06-18T12:53:30.438054+00:00
[2022-06-18 12:53:30,610] {processor.py:161} INFO - Processing /opt/airflow/dags/docker_job/dbt_test.py took 5.211 seconds
[2022-06-18 13:03:37,666] {processor.py:153} INFO - Started process (PID=422) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 13:03:37,671] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 13:03:37,672] {logging_mixin.py:115} INFO - [2022-06-18 13:03:37,672] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 13:03:39,825] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 13:23:28,450] {processor.py:153} INFO - Started process (PID=919) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 13:23:28,553] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 13:23:28,583] {logging_mixin.py:115} INFO - [2022-06-18 13:23:28,583] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 13:23:30,343] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 13:23:33,041] {logging_mixin.py:115} INFO - [2022-06-18 13:23:33,038] {dag.py:2379} INFO - Sync 1 DAGs
[2022-06-18 13:23:34,685] {logging_mixin.py:115} INFO - [2022-06-18 13:23:34,497] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-cdc_load to 2022-06-18T11:23:34.224608+00:00, run_after=2022-06-18T13:23:34.224608+00:00
[2022-06-18 13:23:36,139] {processor.py:161} INFO - Processing /opt/airflow/dags/docker_job/dbt_test.py took 7.948 seconds
[2022-06-18 13:59:42,774] {processor.py:153} INFO - Started process (PID=1350) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 13:59:42,832] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 13:59:42,833] {logging_mixin.py:115} INFO - [2022-06-18 13:59:42,833] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 14:00:00,518] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 14:19:50,796] {processor.py:153} INFO - Started process (PID=1498) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 14:19:50,835] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 14:19:50,836] {logging_mixin.py:115} INFO - [2022-06-18 14:19:50,836] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 14:19:51,767] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 14:22:21,456] {logging_mixin.py:115} INFO - [2022-06-18 14:22:21,456] {dag.py:2379} INFO - Sync 1 DAGs
[2022-06-18 14:36:04,721] {processor.py:153} INFO - Started process (PID=1649) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 14:36:04,723] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 14:36:04,723] {logging_mixin.py:115} INFO - [2022-06-18 14:36:04,723] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 14:36:06,067] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 14:44:21,125] {processor.py:153} INFO - Started process (PID=1761) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 14:44:21,131] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 14:44:21,132] {logging_mixin.py:115} INFO - [2022-06-18 14:44:21,132] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 14:44:23,378] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 14:44:39,965] {logging_mixin.py:115} INFO - [2022-06-18 14:44:39,960] {dag.py:2379} INFO - Sync 1 DAGs
[2022-06-18 14:46:52,439] {logging_mixin.py:115} INFO - [2022-06-18 14:46:52,384] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-cdc_load to 2022-06-18T12:46:52.165083+00:00, run_after=2022-06-18T14:46:52.165083+00:00
[2022-06-18 14:46:52,645] {processor.py:161} INFO - Processing /opt/airflow/dags/docker_job/dbt_test.py took 151.738 seconds
[2022-06-18 14:51:01,651] {processor.py:153} INFO - Started process (PID=1805) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 14:51:01,675] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 14:51:01,692] {logging_mixin.py:115} INFO - [2022-06-18 14:51:01,692] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 14:51:03,025] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 14:52:30,185] {logging_mixin.py:115} INFO - [2022-06-18 14:52:28,469] {dag.py:2379} INFO - Sync 1 DAGs
[2022-06-18 14:59:54,803] {processor.py:153} INFO - Started process (PID=82) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 14:59:54,809] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 14:59:54,809] {logging_mixin.py:115} INFO - [2022-06-18 14:59:54,809] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 14:59:57,338] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 14:59:59,233] {logging_mixin.py:115} INFO - [2022-06-18 14:59:59,200] {dag.py:2379} INFO - Sync 1 DAGs
[2022-06-18 15:00:00,505] {logging_mixin.py:115} INFO - [2022-06-18 15:00:00,490] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-cdc_load to 2022-06-18T13:00:00.479958+00:00, run_after=2022-06-18T15:00:00.479958+00:00
[2022-06-18 15:00:01,477] {processor.py:161} INFO - Processing /opt/airflow/dags/docker_job/dbt_test.py took 6.682 seconds
[2022-06-18 15:03:52,418] {processor.py:153} INFO - Started process (PID=123) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 15:03:52,490] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 15:03:52,491] {logging_mixin.py:115} INFO - [2022-06-18 15:03:52,491] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 15:03:55,752] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 15:05:53,577] {processor.py:164} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3141, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 301, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 755, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 419, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 142, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 247, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 362, in __init__
    self.__connect(first_connect_check=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 605, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 599, in __connect
    connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 578, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 583, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres_source" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 158, in _run_file_processor
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 660, in process_file
    dagbag.sync_to_db()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 615, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 382, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 360, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 193, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 627, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 601, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 68, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 142, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2734, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2821, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1669, in execute
    conn = self._connection_for_bind(bind, close_with_result=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1520, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3095, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 91, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3174, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3145, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2004, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3141, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 301, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 755, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 419, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 142, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 247, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 362, in __init__
    self.__connect(first_connect_check=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 605, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 599, in __connect
    connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 578, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 583, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres_source" to address: Temporary failure in name resolution

(Background on this error at: http://sqlalche.me/e/14/e3q8)
[2022-06-18 15:16:35,590] {processor.py:153} INFO - Started process (PID=195) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 15:16:35,733] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 15:16:35,734] {logging_mixin.py:115} INFO - [2022-06-18 15:16:35,734] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 15:16:45,727] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 15:19:23,033] {processor.py:164} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3141, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 301, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 755, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 419, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 142, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 247, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 362, in __init__
    self.__connect(first_connect_check=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 605, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 599, in __connect
    connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 578, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 583, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres_source" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 158, in _run_file_processor
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 660, in process_file
    dagbag.sync_to_db()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 615, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 382, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 360, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 193, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 627, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 601, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 68, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 142, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2734, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2821, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1669, in execute
    conn = self._connection_for_bind(bind, close_with_result=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1520, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3095, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 91, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3174, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3145, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2004, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3141, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 301, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 755, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 419, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 142, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 247, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 362, in __init__
    self.__connect(first_connect_check=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 605, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 599, in __connect
    connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 578, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 583, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres_source" to address: Temporary failure in name resolution

(Background on this error at: http://sqlalche.me/e/14/e3q8)
[2022-06-18 15:23:10,614] {processor.py:153} INFO - Started process (PID=225) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 15:23:10,676] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 15:23:10,677] {logging_mixin.py:115} INFO - [2022-06-18 15:23:10,677] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 15:23:19,078] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 15:45:29,088] {processor.py:153} INFO - Started process (PID=311) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 15:45:29,092] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 15:45:29,092] {logging_mixin.py:115} INFO - [2022-06-18 15:45:29,092] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 15:45:29,994] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 15:46:29,000] {logging_mixin.py:115} INFO - [2022-06-18 15:46:28,981] {dag.py:2379} INFO - Sync 1 DAGs
[2022-06-18 15:52:56,380] {processor.py:153} INFO - Started process (PID=355) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 15:52:56,383] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 15:52:56,439] {logging_mixin.py:115} INFO - [2022-06-18 15:52:56,439] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 15:53:01,717] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 15:54:33,899] {logging_mixin.py:115} INFO - [2022-06-18 15:54:33,704] {dag.py:2379} INFO - Sync 1 DAGs
[2022-06-18 16:08:33,747] {processor.py:153} INFO - Started process (PID=404) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 16:08:35,987] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 16:08:44,365] {logging_mixin.py:115} INFO - [2022-06-18 16:08:43,033] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 16:09:22,029] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 16:14:37,483] {processor.py:153} INFO - Started process (PID=431) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 16:14:37,491] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 16:14:37,492] {logging_mixin.py:115} INFO - [2022-06-18 16:14:37,492] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 16:14:39,230] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 16:16:36,716] {logging_mixin.py:115} INFO - [2022-06-18 16:16:36,692] {dag.py:2379} INFO - Sync 1 DAGs
[2022-06-18 16:23:54,299] {processor.py:153} INFO - Started process (PID=470) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 16:23:54,330] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 16:23:54,336] {logging_mixin.py:115} INFO - [2022-06-18 16:23:54,333] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 16:24:02,913] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 16:34:46,353] {processor.py:153} INFO - Started process (PID=505) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 16:34:46,391] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 16:34:46,392] {logging_mixin.py:115} INFO - [2022-06-18 16:34:46,392] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 16:34:47,421] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 16:42:23,111] {processor.py:153} INFO - Started process (PID=517) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 16:42:23,591] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 16:42:26,589] {logging_mixin.py:115} INFO - [2022-06-18 16:42:26,241] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 16:43:01,439] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 16:47:51,837] {processor.py:153} INFO - Started process (PID=549) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 16:47:52,038] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 16:47:52,391] {logging_mixin.py:115} INFO - [2022-06-18 16:47:52,346] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 16:48:09,476] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 16:53:29,171] {processor.py:153} INFO - Started process (PID=566) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 16:53:29,373] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 16:53:29,393] {logging_mixin.py:115} INFO - [2022-06-18 16:53:29,393] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 16:54:21,055] {logging_mixin.py:115} INFO - [2022-06-18 16:54:15,245] {timeout.py:67} ERROR - Process timed out, PID: 566
[2022-06-18 16:54:55,997] {logging_mixin.py:115} INFO - [2022-06-18 16:54:31,274] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/docker_job/dbt_test.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/docker_job/dbt_test.py", line 10, in <module>
    from airflow.providers.postgres.operators.postgres import PostgresOperator
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/postgres/operators/postgres.py", line 30, in <module>
    class PostgresOperator(BaseOperator):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/postgres/operators/postgres.py", line 48, in PostgresOperator
    'sql': 'postgresql' if 'postgresql' in wwwutils.get_attr_renderer() else 'sql'
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/www/utils.py", line 533, in get_attr_renderer
    'bash': lambda x: render(x, lexers.BashLexer),
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/docker_job/dbt_test.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.2/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.2/best-practices.html#reducing-dag-complexity, PID: 566
[2022-06-18 16:54:56,003] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 16:55:18,922] {processor.py:164} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3141, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 301, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 755, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 419, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 142, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 247, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 362, in __init__
    self.__connect(first_connect_check=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 605, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 599, in __connect
    connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 578, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 583, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres_source" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 158, in _run_file_processor
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 654, in process_file
    self.update_import_errors(session, dagbag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 541, in update_import_errors
    existing_import_error_files = [x.filename for x in session.query(errors.ImportError.filename).all()]
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2683, in all
    return self._iter().all()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2821, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1669, in execute
    conn = self._connection_for_bind(bind, close_with_result=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1520, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3095, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 91, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3174, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3145, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2004, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3141, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 301, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 755, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 419, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 142, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 247, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 362, in __init__
    self.__connect(first_connect_check=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 605, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 599, in __connect
    connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 578, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 583, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres_source" to address: Temporary failure in name resolution

(Background on this error at: http://sqlalche.me/e/14/e3q8)
[2022-06-18 17:03:32,729] {processor.py:153} INFO - Started process (PID=582) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 17:03:33,032] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 17:03:33,148] {logging_mixin.py:115} INFO - [2022-06-18 17:03:33,148] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 17:03:38,610] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 17:12:09,061] {processor.py:153} INFO - Started process (PID=603) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 17:12:09,750] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 17:12:09,781] {logging_mixin.py:115} INFO - [2022-06-18 17:12:09,781] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 17:12:42,863] {logging_mixin.py:115} INFO - [2022-06-18 17:12:42,832] {timeout.py:67} ERROR - Process timed out, PID: 603
[2022-06-18 17:13:11,010] {logging_mixin.py:115} INFO - [2022-06-18 17:13:04,229] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/docker_job/dbt_test.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/docker_job/dbt_test.py", line 9, in <module>
    from airflow.operators.python_operator import PythonOperator
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python_operator.py", line 22, in <module>
    from airflow.operators.python import (  # noqa
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 77, in <module>
    class PythonOperator(BaseOperator):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 148, in PythonOperator
    ) -> None:
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/docker_job/dbt_test.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.2/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.2/best-practices.html#reducing-dag-complexity, PID: 603
[2022-06-18 17:13:28,994] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 17:14:09,959] {processor.py:164} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3141, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 301, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 755, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 419, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 142, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 247, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 362, in __init__
    self.__connect(first_connect_check=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 605, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 599, in __connect
    connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 578, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 583, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres_source" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 158, in _run_file_processor
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 654, in process_file
    self.update_import_errors(session, dagbag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 541, in update_import_errors
    existing_import_error_files = [x.filename for x in session.query(errors.ImportError.filename).all()]
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2683, in all
    return self._iter().all()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2821, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1669, in execute
    conn = self._connection_for_bind(bind, close_with_result=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1520, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3095, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 91, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3174, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3145, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2004, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3141, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 301, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 755, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 419, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 142, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 247, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 362, in __init__
    self.__connect(first_connect_check=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 605, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 599, in __connect
    connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 578, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 583, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres_source" to address: Temporary failure in name resolution

(Background on this error at: http://sqlalche.me/e/14/e3q8)
[2022-06-18 19:51:56,361] {processor.py:153} INFO - Started process (PID=899) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 19:51:56,367] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 19:51:56,368] {logging_mixin.py:115} INFO - [2022-06-18 19:51:56,368] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 19:51:56,838] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 19:51:57,210] {logging_mixin.py:115} INFO - [2022-06-18 19:51:57,210] {dag.py:2379} INFO - Sync 1 DAGs
[2022-06-18 19:51:57,341] {logging_mixin.py:115} INFO - [2022-06-18 19:51:57,341] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-cdc_load to 2022-06-18T17:51:57.335830+00:00, run_after=2022-06-18T19:51:57.335830+00:00
[2022-06-18 19:51:57,550] {processor.py:161} INFO - Processing /opt/airflow/dags/docker_job/dbt_test.py took 1.224 seconds
[2022-06-18 20:05:03,571] {processor.py:153} INFO - Started process (PID=1104) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 20:05:03,647] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 20:05:03,648] {logging_mixin.py:115} INFO - [2022-06-18 20:05:03,648] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 20:05:05,241] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 20:05:05,950] {logging_mixin.py:115} INFO - [2022-06-18 20:05:05,948] {dag.py:2379} INFO - Sync 1 DAGs
[2022-06-18 20:05:06,235] {logging_mixin.py:115} INFO - [2022-06-18 20:05:06,235] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-cdc_load to 2022-06-18T18:05:06.234982+00:00, run_after=2022-06-18T20:05:06.234982+00:00
[2022-06-18 20:05:06,298] {processor.py:161} INFO - Processing /opt/airflow/dags/docker_job/dbt_test.py took 2.732 seconds
[2022-06-18 20:10:02,456] {processor.py:153} INFO - Started process (PID=1229) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 20:10:02,565] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 20:10:02,566] {logging_mixin.py:115} INFO - [2022-06-18 20:10:02,566] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 20:10:03,357] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 20:14:07,815] {processor.py:153} INFO - Started process (PID=1262) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 20:14:07,830] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 20:14:07,956] {logging_mixin.py:115} INFO - [2022-06-18 20:14:07,956] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 20:14:12,192] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 20:19:01,398] {processor.py:153} INFO - Started process (PID=1329) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 20:19:01,410] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 20:19:01,481] {logging_mixin.py:115} INFO - [2022-06-18 20:19:01,481] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 20:19:02,193] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 20:19:03,197] {logging_mixin.py:115} INFO - [2022-06-18 20:19:03,196] {dag.py:2379} INFO - Sync 1 DAGs
[2022-06-18 20:20:47,489] {logging_mixin.py:115} INFO - [2022-06-18 20:20:47,440] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-cdc_load to 2022-06-18T18:20:47.044014+00:00, run_after=2022-06-18T20:20:47.044014+00:00
[2022-06-18 20:20:48,058] {processor.py:161} INFO - Processing /opt/airflow/dags/docker_job/dbt_test.py took 106.831 seconds
[2022-06-18 20:26:15,953] {processor.py:153} INFO - Started process (PID=1399) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 20:26:15,970] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 20:26:15,979] {logging_mixin.py:115} INFO - [2022-06-18 20:26:15,979] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 20:26:16,619] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 20:26:17,316] {logging_mixin.py:115} INFO - [2022-06-18 20:26:17,316] {dag.py:2379} INFO - Sync 1 DAGs
[2022-06-18 20:26:17,625] {logging_mixin.py:115} INFO - [2022-06-18 20:26:17,591] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-cdc_load to 2022-06-18T18:26:17.590187+00:00, run_after=2022-06-18T20:26:17.590187+00:00
[2022-06-18 20:26:17,759] {processor.py:161} INFO - Processing /opt/airflow/dags/docker_job/dbt_test.py took 1.934 seconds
[2022-06-18 20:37:44,303] {processor.py:153} INFO - Started process (PID=1511) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 20:37:44,478] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 20:37:44,620] {logging_mixin.py:115} INFO - [2022-06-18 20:37:44,620] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 20:37:45,849] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 20:39:13,135] {logging_mixin.py:115} INFO - [2022-06-18 20:39:08,807] {dag.py:2379} INFO - Sync 1 DAGs
[2022-06-18 20:47:20,763] {processor.py:153} INFO - Started process (PID=1567) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 20:47:21,259] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 20:47:21,289] {logging_mixin.py:115} INFO - [2022-06-18 20:47:21,289] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 20:47:42,949] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 20:59:05,096] {processor.py:153} INFO - Started process (PID=1690) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 20:59:05,127] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 20:59:05,128] {logging_mixin.py:115} INFO - [2022-06-18 20:59:05,128] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 20:59:07,366] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 21:17:44,575] {processor.py:153} INFO - Started process (PID=1848) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 21:17:44,665] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 21:17:44,666] {logging_mixin.py:115} INFO - [2022-06-18 21:17:44,666] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 21:17:46,296] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 21:31:38,851] {processor.py:153} INFO - Started process (PID=1901) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 21:31:48,063] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 21:31:53,496] {logging_mixin.py:115} INFO - [2022-06-18 21:31:48,358] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 21:32:41,752] {logging_mixin.py:115} INFO - [2022-06-18 21:32:41,750] {timeout.py:67} ERROR - Process timed out, PID: 1901
[2022-06-18 21:33:03,554] {logging_mixin.py:115} INFO - [2022-06-18 21:32:48,861] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/docker_job/dbt_test.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/docker_job/dbt_test.py", line 98, in <module>
    default_args=default_args)
  File "/opt/airflow/dags/docker_job/dbt_test.py", line 72, in create_dag
    create_source_tables >> create_target_tables >> files_cp >> dbt_cleanup
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 80, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 233, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 169, in _set_relatives
    if not isinstance(task_or_task_list, Sequence):
  File "/usr/local/lib/python3.7/typing.py", line 716, in __instancecheck__
    return self.__subclasscheck__(type(obj))
  File "/usr/local/lib/python3.7/typing.py", line 721, in __subclasscheck__
    return issubclass(cls, self.__origin__)
  File "/usr/local/lib/python3.7/abc.py", line 143, in __subclasscheck__
    return _abc_subclasscheck(cls, subclass)
  File "/usr/local/lib/python3.7/abc.py", line 141, in __subclasscheck__
    def __subclasscheck__(cls, subclass):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/docker_job/dbt_test.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.2/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.2/best-practices.html#reducing-dag-complexity, PID: 1901
[2022-06-18 21:33:09,115] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 21:33:37,541] {processor.py:161} INFO - Processing /opt/airflow/dags/docker_job/dbt_test.py took 118.728 seconds
[2022-06-18 21:37:16,800] {processor.py:153} INFO - Started process (PID=1906) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 21:37:17,186] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 21:37:17,657] {logging_mixin.py:115} INFO - [2022-06-18 21:37:17,556] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 21:37:29,802] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 21:39:55,766] {processor.py:153} INFO - Started process (PID=1913) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 21:39:55,902] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 21:39:57,238] {logging_mixin.py:115} INFO - [2022-06-18 21:39:56,908] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 21:40:27,580] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 21:43:06,171] {logging_mixin.py:115} INFO - [2022-06-18 21:43:06,171] {dag.py:2379} INFO - Sync 1 DAGs
[2022-06-18 21:49:42,826] {processor.py:153} INFO - Started process (PID=1931) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 21:49:42,843] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 21:49:42,844] {logging_mixin.py:115} INFO - [2022-06-18 21:49:42,844] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 21:49:43,975] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 21:54:25,820] {processor.py:153} INFO - Started process (PID=1939) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 21:54:25,824] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 21:54:25,825] {logging_mixin.py:115} INFO - [2022-06-18 21:54:25,825] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 21:54:32,048] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 22:00:46,085] {processor.py:153} INFO - Started process (PID=1945) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 22:00:46,088] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 22:00:46,089] {logging_mixin.py:115} INFO - [2022-06-18 22:00:46,089] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 22:00:46,835] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 22:09:35,378] {processor.py:153} INFO - Started process (PID=1975) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 22:09:35,382] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 22:09:35,383] {logging_mixin.py:115} INFO - [2022-06-18 22:09:35,383] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 22:09:36,635] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 22:10:22,336] {logging_mixin.py:115} INFO - [2022-06-18 22:10:22,336] {dag.py:2379} INFO - Sync 1 DAGs
[2022-06-18 22:10:23,116] {logging_mixin.py:115} INFO - [2022-06-18 22:10:23,116] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-cdc_load to 2022-06-18T20:10:23.104037+00:00, run_after=2022-06-18T22:10:23.104037+00:00
[2022-06-18 22:14:34,665] {processor.py:153} INFO - Started process (PID=1993) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 22:14:34,708] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 22:14:34,708] {logging_mixin.py:115} INFO - [2022-06-18 22:14:34,708] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 22:14:36,374] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 22:19:30,137] {processor.py:153} INFO - Started process (PID=2007) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 22:19:30,494] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 22:19:31,115] {logging_mixin.py:115} INFO - [2022-06-18 22:19:31,115] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 22:19:32,285] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 22:22:04,342] {logging_mixin.py:115} INFO - [2022-06-18 22:22:04,341] {dag.py:2379} INFO - Sync 1 DAGs
[2022-06-18 22:22:04,657] {logging_mixin.py:115} INFO - [2022-06-18 22:22:04,656] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-cdc_load to 2022-06-18T20:22:04.655418+00:00, run_after=2022-06-18T22:22:04.655418+00:00
[2022-06-18 22:29:03,575] {processor.py:153} INFO - Started process (PID=2039) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 22:29:03,756] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 22:29:03,757] {logging_mixin.py:115} INFO - [2022-06-18 22:29:03,757] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 22:29:04,261] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 22:37:46,593] {processor.py:153} INFO - Started process (PID=2062) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 22:37:46,606] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 22:37:46,607] {logging_mixin.py:115} INFO - [2022-06-18 22:37:46,607] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 22:37:47,285] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 22:46:17,798] {processor.py:153} INFO - Started process (PID=2096) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 22:46:17,885] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 22:46:17,887] {logging_mixin.py:115} INFO - [2022-06-18 22:46:17,887] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 22:46:20,358] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 22:48:39,706] {processor.py:164} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3141, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 301, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 755, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 419, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 142, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 247, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 362, in __init__
    self.__connect(first_connect_check=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 605, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 599, in __connect
    connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 578, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 583, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres_source" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 158, in _run_file_processor
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 660, in process_file
    dagbag.sync_to_db()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 615, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 382, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 360, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 193, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 627, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 601, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 68, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 142, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2734, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2821, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1669, in execute
    conn = self._connection_for_bind(bind, close_with_result=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1520, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3095, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 91, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3174, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3145, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2004, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3141, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 301, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 755, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 419, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 142, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 247, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 362, in __init__
    self.__connect(first_connect_check=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 605, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 599, in __connect
    connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 578, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 583, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres_source" to address: Temporary failure in name resolution

(Background on this error at: http://sqlalche.me/e/14/e3q8)
[2022-06-18 22:55:35,707] {processor.py:153} INFO - Started process (PID=2146) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 22:55:35,834] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 22:55:35,835] {logging_mixin.py:115} INFO - [2022-06-18 22:55:35,834] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 22:55:36,285] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 22:55:39,054] {logging_mixin.py:115} INFO - [2022-06-18 22:55:39,028] {dag.py:2379} INFO - Sync 1 DAGs
[2022-06-18 22:58:55,382] {processor.py:153} INFO - Started process (PID=2151) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 22:58:55,449] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 22:58:55,455] {logging_mixin.py:115} INFO - [2022-06-18 22:58:55,455] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 22:58:57,880] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 23:01:46,255] {processor.py:153} INFO - Started process (PID=2166) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 23:01:46,263] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 23:01:46,470] {logging_mixin.py:115} INFO - [2022-06-18 23:01:46,444] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 23:02:07,383] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 23:02:08,431] {logging_mixin.py:115} INFO - [2022-06-18 23:02:08,431] {dag.py:2379} INFO - Sync 1 DAGs
[2022-06-18 23:02:08,773] {logging_mixin.py:115} INFO - [2022-06-18 23:02:08,773] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-cdc_load to 2022-06-18T21:02:08.733249+00:00, run_after=2022-06-18T23:02:08.733249+00:00
[2022-06-18 23:02:09,107] {processor.py:161} INFO - Processing /opt/airflow/dags/docker_job/dbt_test.py took 23.213 seconds
[2022-06-18 23:06:29,104] {processor.py:153} INFO - Started process (PID=2187) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 23:06:29,128] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 23:06:29,129] {logging_mixin.py:115} INFO - [2022-06-18 23:06:29,128] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 23:06:30,360] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 23:09:28,444] {logging_mixin.py:115} INFO - [2022-06-18 23:09:27,479] {dag.py:2379} INFO - Sync 1 DAGs
[2022-06-18 23:16:26,485] {processor.py:153} INFO - Started process (PID=2223) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 23:16:26,546] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 23:16:26,546] {logging_mixin.py:115} INFO - [2022-06-18 23:16:26,546] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 23:16:28,448] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 23:18:15,667] {processor.py:164} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3141, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 301, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 755, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 419, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 142, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 247, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 362, in __init__
    self.__connect(first_connect_check=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 605, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 599, in __connect
    connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 578, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 583, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres_source" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 158, in _run_file_processor
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 660, in process_file
    dagbag.sync_to_db()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 615, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 382, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 360, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 193, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 627, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 601, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 68, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 142, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2734, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2821, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1669, in execute
    conn = self._connection_for_bind(bind, close_with_result=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1520, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3095, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 91, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3174, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3145, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2004, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3141, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 301, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 755, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 419, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 142, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 247, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 362, in __init__
    self.__connect(first_connect_check=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 605, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 599, in __connect
    connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 578, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 583, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres_source" to address: Temporary failure in name resolution

(Background on this error at: http://sqlalche.me/e/14/e3q8)
[2022-06-18 23:19:42,664] {processor.py:153} INFO - Started process (PID=2229) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 23:19:42,779] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 23:19:42,858] {logging_mixin.py:115} INFO - [2022-06-18 23:19:42,858] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 23:19:44,305] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 23:20:41,932] {logging_mixin.py:115} INFO - [2022-06-18 23:20:41,932] {dag.py:2379} INFO - Sync 1 DAGs
[2022-06-18 23:20:42,292] {logging_mixin.py:115} INFO - [2022-06-18 23:20:42,292] {dag.py:2931} INFO - Setting next_dagrun for T-dbt-job-cdc_load to 2022-06-18T21:20:42.291513+00:00, run_after=2022-06-18T23:20:42.291513+00:00
[2022-06-18 23:25:05,276] {processor.py:153} INFO - Started process (PID=2236) to work on /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 23:25:05,284] {processor.py:641} INFO - Processing file /opt/airflow/dags/docker_job/dbt_test.py for tasks to queue
[2022-06-18 23:25:05,285] {logging_mixin.py:115} INFO - [2022-06-18 23:25:05,285] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 23:25:05,990] {processor.py:651} INFO - DAG(s) dict_keys(['T-dbt-job-cdc_load']) retrieved from /opt/airflow/dags/docker_job/dbt_test.py
[2022-06-18 23:26:02,288] {logging_mixin.py:115} INFO - [2022-06-18 23:26:02,286] {dag.py:2379} INFO - Sync 1 DAGs
